{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surrounded-surprise",
   "metadata": {},
   "source": [
    "# 멋진 작사가 만들기\n",
    "## 1. 데이터 다운로드\n",
    "[여기](https://www.kaggle.com/paultimothymooney/poetry/data)에서 Song Lyrics 데이터를 다운로드한다. 저장된 파일을 압축 해제한 후, 모든 txt 파일을 lyrics 폴더를 만들어 그 속에 저장한다. \n",
    "\n",
    "또는 터미널에서 아래의 명령어를 실행한다.\n",
    "```python\n",
    "$ wget https://aiffelstaticprd.blob.core.windows.net/media/documents/song_lyrics.zip\n",
    "$ unzip song_lyrics.zip -d ~/aiffel/lyricist/data/lyrics  \n",
    "#lyrics 폴더에 압축풀기\n",
    "```\n",
    "\n",
    "## 2. 데이터 읽어오기\n",
    "glob 를 활용하여 모든 txt 파일을 읽어온 후, raw_corpus 리스트에 문장 단위로 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "every-taiwan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['They say get ready for the revolution', \"I think it's time we find some sorta solution\", \"Somebody's caught up in the endless pollution\", 'They need to wake up, stop living illusions I know you need to hear this', \"Why won't somebody feel this\", 'This is my wish that we all feel connected', 'This is my wish that nobodies neglected Be like a rocket baby', 'Be like a rocket Take off', 'Just fly, away (ay, ay)']\n"
     ]
    }
   ],
   "source": [
    "import re                  # 정규표현식을 위한 Regex 지원 모듈 (문장 데이터를 정돈하기 위해) \n",
    "import numpy as np         # 변환된 문장 데이터(행렬)을 편하게 처리하기 위해\n",
    "import tensorflow as tf \n",
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담는다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()  # 텍스트를 라인 단위로 끊어서 list 형태로 읽기\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:9]) # 앞에서부터 10라인만 화면에 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-diabetes",
   "metadata": {},
   "source": [
    "## 3. 데이터 정제\n",
    "데이터의 형태를 보고 1차 필터링을 하였다. 길이가 0인 문장과 문장의 끝이 \":\"인 문장을 제외시키고 10개의 문장을 출력하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "federal-flush",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They say get ready for the revolution\n",
      "I think it's time we find some sorta solution\n",
      "Somebody's caught up in the endless pollution\n",
      "They need to wake up, stop living illusions I know you need to hear this\n",
      "Why won't somebody feel this\n",
      "This is my wish that we all feel connected\n",
      "This is my wish that nobodies neglected Be like a rocket baby\n",
      "Be like a rocket Take off\n",
      "Just fly, away (ay, ay)\n",
      "To find your space Take off\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue # 길이가 0인 문장은 건너뛴다.\n",
    "    if sentence[-1] == \":\": continue  # 문장의 끝이 \":\"인 문장은 건너뛴다.\n",
    "    if idx > 9: break   # 일단 문장 10개만 확인해 본다.\n",
    "        \n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-confidence",
   "metadata": {},
   "source": [
    "단어 사전을 만들기 위해서 문장을 일정한 기준으로 나누는 토큰화를 한다. preprocess_sentence() 함수를 만들어 띄어쓰기를 기준으로 문장을 나누고, 다음과 같은 방식으로 데이터를 전처리 한다. \n",
    "\n",
    "1. 문장부호 양쪽으로 공백을 추가한다.     \n",
    "2. 대문자를 소문자로 바꾼다.     \n",
    "3. 특수문자를 모두 제거한다.       \n",
    "\n",
    "언어 모델의 입력 문장 :  \\<start> 나는 밥을 먹었다     \n",
    "언어 모델의 출력 문장 : 나는 밥을 먹었다 \\<end>     \n",
    "    \n",
    "또한 위와 같이 데이터 셋을 만들기 위해 문장의 앞과 뒤에 \\<start>와 \\<end>를 추가하였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "herbal-poland",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "# 전처리, 정규표현식(Regex)을 이용한 필터링 사용\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()       # 소문자로 바꾸고 양쪽 공백을 삭제\n",
    "  \n",
    "    # 아래 3단계를 거쳐 sentence는 스페이스 1개를 delimeter로 하는 소문자 단어 시퀀스로 바뀜\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)        # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)                  # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자(공백문자까지도)를 스페이스 1개로 치환\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    sentence = '<start> ' + sentence + ' <end>'      # 문장 앞뒤로 <start>와 <end> 붙이기\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))   # 필터링 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-seller",
   "metadata": {},
   "source": [
    "위의 정제 함수를 활용하여 정제 데이터를 구축한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "certain-williams",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> they say get ready for the revolution <end>',\n",
       " '<start> i think it s time we find some sorta solution <end>',\n",
       " '<start> somebody s caught up in the endless pollution <end>',\n",
       " '<start> they need to wake up , stop living illusions i know you need to hear this <end>',\n",
       " '<start> why won t somebody feel this <end>',\n",
       " '<start> this is my wish that we all feel connected <end>',\n",
       " '<start> this is my wish that nobodies neglected be like a rocket baby <end>',\n",
       " '<start> be like a rocket take off <end>',\n",
       " '<start> just fly , away ay , ay <end>',\n",
       " '<start> to find your space take off <end>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정제 함수를 사용한 정제 데이터 구축\n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "\n",
    "    corpus.append(preprocess_sentence(sentence))\n",
    "        \n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-prison",
   "metadata": {},
   "source": [
    "이제 문자로 이루어진 데이터를 인공지능이 이해할 수 있도록 숫자로 변환해야 한다.     \n",
    "\n",
    "tf.keras.preprocessing.text.Tokenizer 패키지를 활용하여 정제된 데이터를 토큰화하고, 단어 사전을 만들고, 데이터를 숫자로 변환까지 해주는 벡터화를 한다. \n",
    "\n",
    "지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거한다. LMS에서 제시한 것처럼 문장을 토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습데이터에서 제외하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ahead-stack",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2  45  68 ...   0   0   0]\n",
      " [  2   5 126 ...   0   0   0]\n",
      " [  2 265  16 ...   0   0   0]\n",
      " ...\n",
      " [  2   5  61 ...   0   0   0]\n",
      " [124  73   5 ... 239  28   3]\n",
      " [  2   6 225 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7f683c206110>\n",
      "[[   2   45   68   43  297   28    6 2109    3    0]\n",
      " [   2    5  126   11   16   73   23  204   99 3845]\n",
      " [   2  265   16  635   29   14    6 2963    1    3]]\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 숫자로 변환, 벡터화\n",
    "\n",
    "def tokenize(corpus):\n",
    "    # 텐서플로우에서 제공하는 Tokenizer 패키지를 생성\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000,  # 전체 단어의 개수 \n",
    "        filters=' ',    # 별도로 전처리 로직을 추가 가능. 이번에는 사용하지 않음\n",
    "        oov_token=\"<unk>\"  # out-of-vocabulary\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)   # 구축한 corpus로부터 Tokenizer가 사전을 자동구축한다.\n",
    "\n",
    "    # tokenizer를 활용하여 모델에 입력할 데이터셋을 구축\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   # tokenizer는 구축한 사전으로부터 corpus를 해석해 Tensor로 변환\n",
    "\n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞추기 위한 padding 메소드를 제공\n",
    "    # maxlen의 디폴트값인 None일 때, corpus의 가장 긴 문장을 기준으로 시퀀스 길이가 맞춰진다.\n",
    "    # 여기서는 15로 설정하여 토큰의 개수가 15개를 넘어가는 문장을 제외함. \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, maxlen = 15, padding='post')  \n",
    "\n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)\n",
    "\n",
    "print(tensor[:3, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-theory",
   "metadata": {},
   "source": [
    "텐서 데이터의 숫자는 tokenizer에 구축된 단어 사전의 인덱스이다. 단어 사전이 어떻게 구축되었는지 확인해 본다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "verbal-inspiration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-abuse",
   "metadata": {},
   "source": [
    "생성된 텐서를 소스와 타겟으로 분리하여 모델이 학습할 수 있도록 한다. 여기서 0은 패딩문자 \\<pad>이며, 정해진 입력 시퀀스 길이보다 문장이 짧을 경우 패딩으로 채워 넣은 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "universal-reducing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2   45   68   43  297   28    6 2109    3    0    0    0    0    0]\n",
      "[  45   68   43  297   28    6 2109    3    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1]  # tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성. 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높다.\n",
    "tgt_input = tensor[:, 1:]    # tensor에서 <start>를 잘라내서 타겟 문장을 생성.\n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-substitute",
   "metadata": {},
   "source": [
    "## 4. 평가 데이터셋 분리\n",
    "sklearn 모듈의 train_test_split() 함수를 사용해 훈련 데이터와 평가 데이터를 분리한다. 단어장의 크기는 12,000으로 설정하고, 총 데이터의 20%를 평가 데이터셋으로 분리하였다.\n",
    "\n",
    "Source Train: (124960, 14)            \n",
    "Target Train: (124960, 14)\n",
    "\n",
    "노드에서는 위와 같은 결과가 나오지 않는다면 데이터 정제 과정을 다시 해 보라고 하는데, 방법을 잘 모르겠다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spread-maryland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (140599, 14)\n",
      "Target Train: (140599, 14)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 평가 데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, \n",
    "                                                          tgt_input, \n",
    "                                                          test_size=0.2,  \n",
    "                                                          shuffle=True)\n",
    "\n",
    "print(\"Source Train:\", enc_train.shape) \n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-yukon",
   "metadata": {},
   "source": [
    "텐서플로우를 활용할 경우 텐서로 생성된 데이터를 이용해 tf.data.Dataset객체를 생성하는 방법을 흔히 사용한다. 데이터셋을 텐서 형태로 생성하였기 때문에 tf.data.Dataset.from_tensor_slices() 메소드를 이용해 tf.data.Dataset객체를 생성한다. 훈련 데이터와 평가 데이터를 각각 tf.data.Dataset객체로 생성하였다.\n",
    "\n",
    "이 부분은 이해가 잘 가지 않아 조원의 도움으로 해결하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "individual-witch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.data.Dataset.from_tensor_slices() 메소드를 이용해 tf.data.Dataset객체 생성\n",
    "# 학습 데이터\n",
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1    # tokenizer가 구축한 단어사전 내 12000개와, 여기 포함되지 않은 0:<pad>를 포함하여 12001개\n",
    "\n",
    "dataset1 = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE)\n",
    "dataset1 = dataset1.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "timely-quality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.data.Dataset.from_tensor_slices() 메소드를 이용해 tf.data.Dataset객체 생성\n",
    "# 평가 데이터\n",
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1    # tokenizer가 구축한 단어사전 내 12000개와, 여기 포함되지 않은 0:<pad>를 포함하여 12001개\n",
    "\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices((enc_val, dec_val)).shuffle(BUFFER_SIZE)\n",
    "dataset2 = dataset2.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-liquid",
   "metadata": {},
   "source": [
    "## 5. 인공지능 만들기\n",
    "모델은 tf.keras.Model을 Subclassing하는 방식으로 만들 것이다. 모델은 1개의 Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성되어 있다.\n",
    "\n",
    "> Embedding 레이어는 단어 사전의 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꿔 준다. 이 워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현(representation)으로 사용된다. embedding_size 는 워드 벡터의 차원수, 즉 단어가 추상적으로 표현되는 크기이다. 값이 커질수록 단어의 추상적인 특징들을 더 잡아낼 수 있지만, 충분한 데이터가 주어지지 않으면 오히려 혼란만을 야기할 수 있다. \n",
    "\n",
    "> LSTM 레이어의 hidden state 의 차원수인 hidden_size는 모델에 얼마나 많은 일꾼을 둘 것인가? 로 이해해도 된다. 그 일꾼들은 모두 같은 데이터를 보고 각자의 생각을 가지는데, 충분한 데이터가 주어지면 올바른 결정을 내리지만 그렇지 않으면 배가 산으로 간다.\n",
    "\n",
    "위의 설명을 참고하여 모델의 Embedding Size와 Hidden Size를 조절하며 10 Epoch 안에 val_loss 값을 2.2 수준으로 줄일 수 있도록 모델을 설계하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "united-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.Model을 Subclassing하는 방식으로 모델 만들기\n",
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size) # 단어 사전의 인덱스값->인덱스 번째의 워드 벡터\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 2048\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-fortune",
   "metadata": {},
   "source": [
    "설계한 모델에 데이터를 넣어 확인해 본다. 모델의 최종 출력 텐서 shape=(256, 14, 12001)이다. 12001은 Dense 레이어의 출력 차원수이며, 12001개의 단어 중 어느 단어의 확률이 가장 높을지를 모델링한다. 256은 지정한 배치 사이즈이고, dataset.take(1)를 통해서 1개의 배치, 즉 256개의 문장 데이터를 가져온 것이다.\n",
    "\n",
    "LSTM 레이어에서 return_sequences=True의 뜻은 LSTM은 자신에게 입력된 시퀀스의 길이만큼 동일한 길이의 시퀀스를 출력한다는 의미이다. 데이터셋의 max_len이 15이므로 길이 15의 문장을 출력한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "judicial-louisiana",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[ 1.33403722e-04,  1.27855950e-04,  1.60429350e-04, ...,\n",
       "          9.37719524e-05,  1.52588356e-04,  6.07635548e-06],\n",
       "        [ 2.15726046e-04,  3.80283804e-04,  2.20275702e-04, ...,\n",
       "         -1.39630181e-04,  3.19607818e-04,  3.66073909e-05],\n",
       "        [ 4.14136011e-04,  2.91649223e-04,  2.40194655e-04, ...,\n",
       "         -5.22263465e-04,  6.97071955e-04,  8.39797649e-05],\n",
       "        ...,\n",
       "        [ 3.75354837e-04,  1.74196233e-04, -2.74455106e-05, ...,\n",
       "         -4.26990911e-04,  4.61092015e-04, -1.00597576e-03],\n",
       "        [ 2.36141161e-04,  6.89809560e-04,  7.99637928e-05, ...,\n",
       "         -4.09715372e-04,  3.91217152e-04, -9.69381304e-04],\n",
       "        [-1.08435794e-04,  9.07401904e-04,  3.38523969e-04, ...,\n",
       "         -1.44875696e-04,  5.23680879e-04, -7.57600938e-04]],\n",
       "\n",
       "       [[ 1.33403722e-04,  1.27855950e-04,  1.60429350e-04, ...,\n",
       "          9.37719524e-05,  1.52588356e-04,  6.07635548e-06],\n",
       "        [ 2.28188670e-04,  2.33416751e-04,  1.22237339e-04, ...,\n",
       "         -4.15752438e-05,  2.62072601e-04,  1.04208921e-04],\n",
       "        [ 5.16230182e-04,  5.70106611e-04, -2.18047106e-04, ...,\n",
       "         -2.57941952e-04,  4.27485065e-04,  2.12998159e-04],\n",
       "        ...,\n",
       "        [-2.12063576e-04, -3.19832005e-04,  1.60563970e-03, ...,\n",
       "         -1.05639151e-03,  1.33414741e-03,  4.50839638e-04],\n",
       "        [-3.61623388e-04, -4.24621539e-04,  2.14555976e-03, ...,\n",
       "         -9.96643794e-04,  1.41275313e-03,  1.45121900e-04],\n",
       "        [-5.08786528e-04, -4.88026621e-04,  2.63158418e-03, ...,\n",
       "         -9.07833979e-04,  1.47912942e-03, -1.71014341e-04]],\n",
       "\n",
       "       [[ 1.33403722e-04,  1.27855950e-04,  1.60429350e-04, ...,\n",
       "          9.37719524e-05,  1.52588356e-04,  6.07635548e-06],\n",
       "        [ 2.52479978e-04, -2.29092955e-04,  2.82867230e-04, ...,\n",
       "         -1.68887389e-04,  1.67937862e-04, -1.41414639e-05],\n",
       "        [ 4.32164263e-04, -3.63070751e-04,  3.88945715e-04, ...,\n",
       "         -5.55410748e-04, -1.68942992e-04,  5.35140534e-05],\n",
       "        ...,\n",
       "        [-7.94654945e-04, -5.01082803e-04, -3.23483662e-04, ...,\n",
       "          5.45904040e-04,  4.60867857e-04,  5.68409509e-04],\n",
       "        [-9.85488179e-04, -5.48993179e-04, -1.77400871e-04, ...,\n",
       "          6.82801125e-04,  7.53924658e-04,  6.14190823e-04],\n",
       "        [-1.03434781e-03, -6.90985937e-04,  1.80731266e-04, ...,\n",
       "          6.27786852e-04,  9.78983240e-04,  5.19080553e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.33403722e-04,  1.27855950e-04,  1.60429350e-04, ...,\n",
       "          9.37719524e-05,  1.52588356e-04,  6.07635548e-06],\n",
       "        [ 2.28067962e-04,  1.97724352e-04,  2.27683195e-04, ...,\n",
       "          3.17274244e-04,  1.43425059e-04,  1.02682134e-04],\n",
       "        [ 3.09940107e-04,  2.88316951e-04,  1.29686436e-04, ...,\n",
       "          1.29739652e-04,  2.16468528e-04,  2.95124599e-04],\n",
       "        ...,\n",
       "        [ 1.28215715e-05,  4.92408690e-05,  3.11372266e-03, ...,\n",
       "         -5.26222129e-06,  1.34252815e-03, -4.88109596e-04],\n",
       "        [-1.76058486e-04, -6.91578389e-05,  3.45057691e-03, ...,\n",
       "         -4.21654477e-05,  1.47888472e-03, -6.86588464e-04],\n",
       "        [-3.60369304e-04, -1.60912386e-04,  3.73476883e-03, ...,\n",
       "         -4.12815352e-05,  1.59345474e-03, -8.87256989e-04]],\n",
       "\n",
       "       [[ 1.33403722e-04,  1.27855950e-04,  1.60429350e-04, ...,\n",
       "          9.37719524e-05,  1.52588356e-04,  6.07635548e-06],\n",
       "        [-2.41492586e-07,  2.59011285e-04,  4.11519664e-04, ...,\n",
       "         -1.63372577e-04,  1.32354908e-04, -1.55856833e-06],\n",
       "        [-2.73541373e-04,  3.13110213e-04,  6.02249813e-04, ...,\n",
       "         -4.37688926e-04,  4.42929508e-04, -1.13253031e-04],\n",
       "        ...,\n",
       "        [-7.45559402e-04,  3.78499826e-04,  2.03946489e-03, ...,\n",
       "         -6.32273208e-04,  1.14137807e-03,  8.22165675e-05],\n",
       "        [-7.87848432e-04,  1.66358004e-04,  2.49442644e-03, ...,\n",
       "         -6.30977331e-04,  1.25912402e-03, -2.36779582e-04],\n",
       "        [-8.45155620e-04, -5.99614759e-06,  2.89944187e-03, ...,\n",
       "         -5.88279800e-04,  1.36179675e-03, -5.52058453e-04]],\n",
       "\n",
       "       [[ 1.33403722e-04,  1.27855950e-04,  1.60429350e-04, ...,\n",
       "          9.37719524e-05,  1.52588356e-04,  6.07635548e-06],\n",
       "        [-1.45462172e-06,  1.38392919e-04,  2.78362131e-04, ...,\n",
       "          6.14113233e-04,  1.59086208e-04,  7.90240520e-05],\n",
       "        [-1.43576690e-04,  3.69957939e-04,  1.00274126e-04, ...,\n",
       "          9.85731138e-04,  3.08346003e-04,  1.76338537e-04],\n",
       "        ...,\n",
       "        [-4.31672117e-04, -9.99259762e-04,  1.83680817e-03, ...,\n",
       "          2.98225263e-04,  1.01414067e-03,  1.82666801e-04],\n",
       "        [-5.59889595e-04, -1.01166160e-03,  2.28291331e-03, ...,\n",
       "          1.60767784e-04,  1.10073283e-03, -1.18557400e-04],\n",
       "        [-6.86861400e-04, -9.84797138e-04,  2.69146683e-03, ...,\n",
       "          7.43256824e-05,  1.17966474e-03, -4.13836999e-04]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 데이터의 문장\n",
    "for src_sample, tgt_sample in dataset1.take(1): break\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "identical-transformation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[ 1.3340372e-04,  1.2785595e-04,  1.6042935e-04, ...,\n",
       "          9.3771952e-05,  1.5258836e-04,  6.0763555e-06],\n",
       "        [-6.9560818e-05,  2.6105670e-04,  1.3569099e-04, ...,\n",
       "          2.4479377e-04,  7.9330523e-05,  1.8231356e-05],\n",
       "        [-4.9915659e-05,  3.7813213e-04,  5.8374644e-05, ...,\n",
       "          2.6723661e-04,  4.7734444e-05,  2.4334100e-04],\n",
       "        ...,\n",
       "        [-5.3605105e-04, -7.9727601e-05, -1.8469099e-04, ...,\n",
       "          1.7451844e-03,  3.1911273e-04,  3.6636618e-04],\n",
       "        [-5.7039224e-04, -2.2827552e-04,  4.3931641e-04, ...,\n",
       "          1.5137453e-03,  5.9463142e-04,  2.0706627e-04],\n",
       "        [-6.1125628e-04, -3.4796022e-04,  1.0443634e-03, ...,\n",
       "          1.2726050e-03,  8.3594111e-04,  1.9916266e-05]],\n",
       "\n",
       "       [[ 1.3340372e-04,  1.2785595e-04,  1.6042935e-04, ...,\n",
       "          9.3771952e-05,  1.5258836e-04,  6.0763555e-06],\n",
       "        [ 9.9955585e-05,  3.7408431e-04,  1.4047005e-04, ...,\n",
       "          2.2956016e-04,  1.2061541e-04,  5.3714724e-05],\n",
       "        [ 8.0459715e-05,  7.4725552e-04,  3.5044024e-04, ...,\n",
       "          3.9376231e-04,  1.7074808e-04,  4.9042275e-05],\n",
       "        ...,\n",
       "        [ 6.8543589e-04,  5.2738679e-04,  1.2966088e-03, ...,\n",
       "          1.7853543e-04,  1.1018566e-03,  1.8217357e-05],\n",
       "        [ 5.9334323e-04,  2.6848636e-04,  1.7495709e-03, ...,\n",
       "          9.8296732e-06,  1.1973733e-03, -1.1998427e-04],\n",
       "        [ 4.7022145e-04,  2.1728951e-05,  2.1812734e-03, ...,\n",
       "         -1.5601893e-04,  1.2906721e-03, -3.1231897e-04]],\n",
       "\n",
       "       [[-1.6228721e-04,  4.6201316e-05,  2.7600469e-04, ...,\n",
       "         -8.0136699e-05,  4.5584700e-05, -7.7688564e-05],\n",
       "        [-4.8823617e-04,  5.1373470e-05,  3.4836677e-04, ...,\n",
       "         -6.5176544e-05, -1.5011772e-04, -6.5551932e-05],\n",
       "        [-4.3956705e-04, -8.4148611e-05,  2.9446298e-04, ...,\n",
       "         -3.1388502e-04,  1.2354752e-04, -6.6635766e-05],\n",
       "        ...,\n",
       "        [-2.3047938e-05,  7.5695957e-06, -6.5095589e-04, ...,\n",
       "         -1.3895915e-03,  2.4868934e-03, -9.3586207e-04],\n",
       "        [-3.2163836e-05,  6.9882713e-05, -5.3840212e-04, ...,\n",
       "         -1.3188726e-03,  2.6405002e-03, -1.0620602e-03],\n",
       "        [ 1.2559352e-04,  2.3715367e-04, -4.3566944e-04, ...,\n",
       "         -1.1566739e-03,  2.4128724e-03, -9.9652365e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.3340372e-04,  1.2785595e-04,  1.6042935e-04, ...,\n",
       "          9.3771952e-05,  1.5258836e-04,  6.0763555e-06],\n",
       "        [ 1.4161761e-04,  1.6447408e-04,  2.6319886e-04, ...,\n",
       "          8.6530097e-05,  1.2715599e-04, -1.9581848e-05],\n",
       "        [ 2.8612488e-04,  4.4970150e-04,  9.7215729e-05, ...,\n",
       "         -2.4428804e-04,  1.2463047e-04,  2.7404124e-06],\n",
       "        ...,\n",
       "        [ 1.5881813e-05, -3.2528522e-04,  7.5103203e-04, ...,\n",
       "          2.0285457e-04,  7.9131930e-04, -5.3496851e-04],\n",
       "        [-7.9691439e-05, -5.0276308e-04,  1.2648044e-03, ...,\n",
       "          9.9513811e-05,  9.6063880e-04, -6.5648946e-04],\n",
       "        [-1.8782345e-04, -6.2403601e-04,  1.7525643e-03, ...,\n",
       "          2.1635557e-05,  1.0937633e-03, -7.9362706e-04]],\n",
       "\n",
       "       [[ 3.2446304e-05, -4.2869648e-04,  9.4828749e-05, ...,\n",
       "         -3.3365178e-04, -3.8282011e-05, -6.6305882e-05],\n",
       "        [-4.0498860e-05, -9.1197441e-04,  1.5686380e-04, ...,\n",
       "         -5.8281684e-04, -5.6562250e-05, -1.4688025e-04],\n",
       "        [ 1.8232861e-04, -8.6931797e-04, -1.2967925e-04, ...,\n",
       "         -8.3691231e-04, -3.6231831e-06, -1.9150146e-04],\n",
       "        ...,\n",
       "        [-6.2845252e-04,  1.2205143e-03, -4.4715535e-04, ...,\n",
       "         -1.0621301e-03,  5.9986301e-04,  5.7879410e-04],\n",
       "        [-6.9975911e-04,  1.1751073e-03, -4.2609725e-04, ...,\n",
       "         -8.8540453e-04,  5.4673984e-04,  6.0825649e-04],\n",
       "        [-6.4507703e-04,  1.1914860e-03, -3.1737817e-04, ...,\n",
       "         -1.0786282e-03,  3.5912683e-04,  4.5123050e-04]],\n",
       "\n",
       "       [[ 1.3340372e-04,  1.2785595e-04,  1.6042935e-04, ...,\n",
       "          9.3771952e-05,  1.5258836e-04,  6.0763555e-06],\n",
       "        [ 1.6640122e-04,  4.2589466e-04,  9.2774699e-06, ...,\n",
       "          2.8990139e-04,  3.4269271e-04,  8.9500565e-05],\n",
       "        [ 2.9460201e-04,  3.4109320e-04, -1.3687941e-05, ...,\n",
       "          4.8442732e-04,  5.5533514e-04, -4.0118313e-05],\n",
       "        ...,\n",
       "        [-7.9723884e-04,  8.3220535e-04,  1.2023258e-03, ...,\n",
       "          1.1113040e-03,  1.1212073e-03,  5.3743186e-04],\n",
       "        [-1.2062201e-03,  7.5713993e-04,  1.3154313e-03, ...,\n",
       "          1.3192924e-03,  1.3562265e-03,  5.8093027e-04],\n",
       "        [-1.3649977e-03,  5.2396650e-04,  1.6164142e-03, ...,\n",
       "          1.3008016e-03,  1.5187779e-03,  4.6377582e-04]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가 데이터의 문장\n",
    "for src_sample, tgt_sample in dataset2.take(1): break\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-orchestra",
   "metadata": {},
   "source": [
    "위에서 설계한 모델은 입력 시퀀스의 길이를 모르므로 Output Shape를 알 수 없으나 모델의 파라미터 사이즈는 측정된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "inner-matthew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  18882560  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  33562624  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  24590049  \n",
      "=================================================================\n",
      "Total params: 80,107,489\n",
      "Trainable params: 80,107,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "improved-skiing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "549/549 [==============================] - 212s 386ms/step - loss: 3.6320 - val_loss: 3.2275\n",
      "Epoch 2/10\n",
      "549/549 [==============================] - 216s 394ms/step - loss: 3.0565 - val_loss: 2.9677\n",
      "Epoch 3/10\n",
      "549/549 [==============================] - 217s 395ms/step - loss: 2.7775 - val_loss: 2.7736\n",
      "Epoch 4/10\n",
      "549/549 [==============================] - 218s 396ms/step - loss: 2.5216 - val_loss: 2.6390\n",
      "Epoch 5/10\n",
      "549/549 [==============================] - 242s 442ms/step - loss: 2.2733 - val_loss: 2.5319\n",
      "Epoch 6/10\n",
      "549/549 [==============================] - 247s 450ms/step - loss: 2.0351 - val_loss: 2.4479\n",
      "Epoch 7/10\n",
      "549/549 [==============================] - 245s 446ms/step - loss: 1.8092 - val_loss: 2.3892\n",
      "Epoch 8/10\n",
      "549/549 [==============================] - 217s 396ms/step - loss: 1.6027 - val_loss: 2.3472\n",
      "Epoch 9/10\n",
      "549/549 [==============================] - 217s 395ms/step - loss: 1.4218 - val_loss: 2.3250\n",
      "Epoch 10/10\n",
      "549/549 [==============================] - 213s 389ms/step - loss: 1.2682 - val_loss: 2.3229\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "\n",
    "history = []\n",
    "epochs = 10\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(dataset1,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=256,\n",
    "                    validation_data=dataset2,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-mortality",
   "metadata": {},
   "source": [
    "학습 결과를 그래프로 그려 보았다. Loss가 점점 떨어지는 것을 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "friendly-branch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# training loss: \"파란색 점\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# validation loss: \"파란 실선\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-practice",
   "metadata": {},
   "source": [
    "모델에게 시작 문장을 전달하면 모델이 시작 문장을 바탕으로 작문을 진행하게 하는 generate_text 함수를 만들었다. 텍스트를 생성해야 하는데, 타겟 문장과 소스 문장이 없고, 테스트 데이터셋을 생성하지 않았기 때문에 while문을 써서 문장을 생성하게 된다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "artistic-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 텍스트를 실제로 생성할때는 루프를 돌면서 단어 하나씩 생성\n",
    "    while True:\n",
    "        predict = model(test_tensor)  # 입력받은 문장의 텐서를 입력\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   # 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됨 \n",
    "\n",
    "        # 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙인다.\n",
    "        test_tensor = tf.concat([test_tensor, \n",
    "                                    tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 모델이 <end>를 예측했거나, max_len에 도달하지 않았다면  while 루프를 또 돌면서 다음 단어를 예측해야 합니다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   # 최종적으로 모델이 생성한 자연어 문장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-discovery",
   "metadata": {},
   "source": [
    "위의 함수를 사용하여 문장을 생성해 보았다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "processed-bumper",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love it when you call me big poppa <end> '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "boring-medicine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> you are the one who grows distant <end> '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> you are\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "mounted-wyoming",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> yesterday is coming to the usa sail on , sail on <end> '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> yesterday\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-greek",
   "metadata": {},
   "source": [
    "## 루브릭 평가문항\t\n",
    "1. 가사 텍스트 생성 모델이 정상적으로 동작하는가?(텍스트 제너레이션 결과가 그럴듯한 문장으로 생성되는가?)     \n",
    "\n",
    "다양한 단어로 문장을 시작하였을 때, 의미는 이상하지만 3 문장이 모두 그럴듯한 문장이 생성되었다. \n",
    "\n",
    "2. 데이터의 전처리와 데이터셋 구성 과정이 체계적으로 진행되었는가?(특수문자 제거, 토크나이저 생성, 패딩처리 등의 과정이 빠짐없이 진행되었는가?)\n",
    "\n",
    "데이터 전처리(특수문자 제거, 토크나이저 생성, 패딩처리 등의 과정)와 데이터셋 구성 과정은 체계적으로 진행되었다. \n",
    "\n",
    "3. 텍스트 생성모델이 안정적으로 학습되었는가?(텍스트 생성모델의 validation loss가 2.2 이하로 낮아졌는가?)       \n",
    "모델의 Embedding Size와 Hidden Size를 변경해 가며 validation loss를 2.2 이하로 낮추려고 시도하였으나 2.2 이하로 내려가지 않았다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-miniature",
   "metadata": {},
   "source": [
    "## 후기\n",
    "### 이번 프로젝트에서 어려웠던 점\n",
    "- 모델 성능 개선      \n",
    "Embedding Size와 Hidden Size를 다양하게 조절하여 텍스트 생성 모델의 validation loss를 2.2 이하로 내려가려고 시도하였으나 결국 2.2 이하로 낮추지 못하였다. 학습 시간이 오래 걸려서 파라미터를 더 많이 바꿀 수 없어서 아쉽다. \n",
    "- 텐서로 생성된 데이터를 tf.data.Dataset객체를 생성        \n",
    "처음에는 데이터셋 분리를 객체 생성 다음에 했기 때문에 데이터셋 객체 생성이 왜 있어야 하는지 몰랐다. 조원들에게 질문을 하여 순서가 바뀌었다는 것을 깨달았다. \n",
    "\n",
    "### 프로젝트를 진행하면서 알게된 점\n",
    "이번 프로젝트를 통해 이전까지는 무작정 따라하던 것들의 의미를 조금 알게 되었다. 토크나이저, 패딩, Embedding Size, LSTM의 Hidden Size 등의 개념이 노드에 나왔고, 이전에 배웠던 CS231n 강의에서도 배운 내용이 생각이 났기 때문이다. 아직 이해가 잘 되지 않는 부분도 있지만 조금이나마 이해할 수 있어서 기쁘다. \n",
    "\n",
    "\n",
    "### 프로젝트를 진행하면서 아직 모호한 점\n",
    "텐서로 생성된 데이터를 tf.data.Dataset객체를 생성하는 부분이 사실 잘 이해가 가지 않는다. Wikidocs에서는 \"모든 데이터세트는 tf.data.Datasets로 노출되므로 사용이 간편한 고성능 입력 파이프라인이 가능하다\"라고 나와 있는데, 그 의미를 잘 모르겠다. \n",
    "\n",
    "### 자기 다짐\n",
    "조원들이 자신들의 모델에 대해 잠시 설명해주는 시간이 있었다. 한 조원은 모델에 같은 레이어를 여러 개 쌓기도 하고, dropout 등 다른 것들을 쌓았다고 했다. 그러나 나는 아직까지 모델을 설계하는 방법을 잘 모르고 그 의미를 잘 모르겠다. 강의도 듣고 노드를 공부하지만 아직도 많이 부족한 것 같다. 또한 프로젝트를 하면서 쓰이는 코드도 혼자서는 쓰지 못하고, 의미도 제대로 이해하지 못하는 것 같다. 그래서 프로젝트를 하면서도 제대로 하고 있는건지 잘 모르겠고, 어떻게 공부해야 하는 건지 몰라 막막하다. 단지 프로젝트 제출하는 것에만 만족하기에는 뭔가 부족하다는 생각이 든다. 하지만 프로젝트의 모든 부분을 이해하기에는 체력이 잘 안 따라주고, 시간도 부족하다. 앞으로 어떻게 하면 좋을지에 대해서 생각해 봐야겠다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
