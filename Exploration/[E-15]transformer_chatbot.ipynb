{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "popular-vegetation",
   "metadata": {},
   "source": [
    "# 15. 프로젝트: 한국어 데이터로 챗봇 만들기\n",
    "영어로 만들었던 챗봇을 한국어 데이터로 바꿔서 훈련시킨다.\n",
    "\n",
    "## 이론 정리\n",
    "- AIFFEL 과정에서 배운 내용과 ['딥러닝을 이용한 자연어 처리 입문'](https://wikidocs.net/31379)을 참고하여 정리하였다. \n",
    "\n",
    "## 번역기와 챗봇\n",
    "번역기를 만들 때 사용하는 대표적인 모델은 '인코더와 디코더'의 아키텍처로 구성되어 있다. 인코더에 입력 문장이 들어가고, 디코더는 이에 상응하는 출력 문장을 생성한다. 즉 입력문장과 출력 문장 2가지 병렬 구조로 구성된 데이터셋을 훈련하여 새로운 문장이 들어왔을 때 그에 상응하는 출력문장을 생성할 수 있다. 이와 같은 구조를 이용하여 챗봇도 만들 수 있다. \n",
    "\n",
    "#### 훈련 데이터셋의 구성(질문-답변)\n",
    "- 입력문장: '1지망 학교 떨어졌어'\n",
    "- 출력문장: '위로해 드립니다.'    \n",
    "병렬적으로 구성된 데이터셋이다. 질문에 대해서 대답을 하도록 구성된 데이터셋을 인코더와 디코더 구조로 학습하여 주어진 질문에 답할 수 있는 챗봇을 만들 수 있다. \n",
    "\n",
    "## 트랜스포머의 주요 하이퍼파라미터\n",
    "- $d_{model}$: 트랜스포머의 인코더와 디코더에서의 정해진 입력과 출력의 크기, 임베딩 벡터의 차원. 이 차원은 여러 층의 인코더와 디코더로 값을 보낼 때도 계속 유지된다. 논문에서는 512이다. \n",
    "- num\\_layers: 트랜스포머에서의 인코더와 디코더의 층의 개수, 논문에서는 6개의 층으로 구성되었다. \n",
    "- num\\_heads: 병렬 어텐션의 개수, 논문에서는 8개이다. \n",
    "- $d_{ff}$(units): 트랜스포머 내부에 존재하는 피드 포워드 신경망의 은닉층의 크기이며, 논문에서는 2048이다.\n",
    "\n",
    "## 트랜스포머의 인코더와 디코더\n",
    "트랜스포머 역시 인코더와 디코더의 구성을 가지기 때문에 입력 문장을 넣으면 출력 문장을 생성한다. 그러나 기존의 RNN을 사용한 모델과 달리 트랜스포머는 RNN을 없애고 Attention 기법만을 사용하고, 인코더와 디코더를 여러 개 쌓은 구조로 되어 있다. \n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/6a4a5e17-5127-451f-a199-8028c2f771cd/Screenshot%20from%202021-03-04%2011-06-12.png)\n",
    "\n",
    "### Positional Encoding\n",
    "아래의 그림은 트랜스포머의 인코더와 디코더 구조를 간단히 그림으로 표현한 것이다. 그림의 Encoders와 Decoders는 6개의 인코더와 디코더를 의미한다. 먼저 단어를 원-핫 벡터로 만든 후, 차원을 줄이기 위해서 embedding layer를 지나간다. 여기까지는 RNN과 같은 방식이다. 그러나 인코더와 디코더에 단어 벡터를 넣기 전 Positional Encoding이라는 단계를 하나 더 거친다. \n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/541a9083-c5e3-4eb2-ac2f-ce805dfb63a1/Screenshot%20from%202021-03-04%2011-11-03.png)\n",
    "\n",
    "순차적으로 단어를 집어 넣는 RNN과 달리 트랜스포머는 한꺼번에 입력 문장을 넣기 때문에 단어의 위치 정보(어순)를 알려주기 위해서 Positional Encoding을 해주어야만 한다. 아래의 그림과 같이 positional encoding과 embedding vector를 각 엘레먼트 별로(element-wise) 더해준다.\n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/be37636e-6cda-40c5-95dc-bc5bc89c3136/Screenshot%20from%202021-03-04%2011-11-08.png)\n",
    "\n",
    "트랜스포머는 사인함수와 코사인함수의 값을 임베딩 벡터에 더해주어 단어의 순서 정보를 더해준다. 임베딩 벡터의 각 차원의 인덱스가 짝수인 경우에는 사인함수의 값을, 홀수인 경우에는 코사인 함수의 값을 사용한다. \n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/66af2db8-7bdf-4295-bf70-975f6864ba80/Screenshot%20from%202021-03-04%2011-11-17.png)\n",
    "\n",
    "- $d_{model}$: 임베딩 벡터의 차원\n",
    "- pos: 입력 문장에서의 임베딩 벡터의 위치\n",
    "- i: 임베딩 벡터 내의 차원의 인덱스\n",
    "  \n",
    "  Q. 최대 문장의 길이가 50, 워드 임베딩 차원을 512로 하는 포지셔널 인코딩 행렬의 모습은 어떻게 되는가? 또한 포지셔널 인코딩 레이어를 사용하여 표현해 보아라. \n",
    "  50x512, positional_encoding(50, 512)\n",
    "  \n",
    "### Attention\n",
    "  트랜스포머에서 가장 핵심적인 개념은 Attention이며, 어텐션은 단어들 간 유사도를 구하는 매커니즘이다. 그리고 Attention에서 핵심적인 것은 Query, Key, Value이다. 우선 쿼리, 키, 밸류는 입력 문장의 모든 단어들의 벡터라는 사실을 잊지 말아야 한다.\n",
    "  \n",
    "쿼리는 말 그대로 질문을 하는 것이다. 즉 알아보고자 하는 단어가 쿼리이고 문장의 모든 단어가 키이다. 알고자 하는 단어(쿼리)가 문장의 모든 단어(키들)와 얼마만큼의 유사도를 가지고 있는지를 구한다. 여기서 구한 쿼리와 키와의 유사도를 키와 매핑(mapping)되어 있는 값(밸류)에 반영한다. 유사도가 반영된 값을 모두 하나로 더한 것이 어텐션 값(Attention Value)이다. \n",
    "  \n",
    "  ![](https://images.velog.io/images/guide333/post/67ec148c-dd7f-47d1-821f-0090127a361a/Screenshot%20from%202021-03-04%2011-51-25.png)\n",
    "  \n",
    "트랜스포머에서는 아래와 같은 3가지의 어텐션을 사용한다. \n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/7a2ddc3b-9126-49fd-bbc3-6068dcc86836/Screenshot%20from%202021-03-04%2011-52-37.png)\n",
    "\n",
    "인코더 셀프 어텐션은 인코더에서, 디코더 셀프 어텐션과 인코더-디코더 어텐션은 디코더에서 이루어진다. \n",
    "\n",
    "- 인코더 셀프 어텐션: 인코더의 입력으로 들어간 문장 내 단어들의 유사도를 구한다.\n",
    "- 디코더 셀프 어텐션: 단어를 1개씩 생성하는 디코더가 이미 생성된 앞 단어와의 유사도를 구한다. (뒤의 단어와의 유사도를 알지 못하도록 마스크를 씌워준다.)\n",
    "- 인코더-디코더 어텐션: 인코더에 입력된 단어들과 디코더의 단어 간의 유사도를 구한다. \n",
    "\n",
    "### Q, K, V 구하기 \n",
    "Q, K, V는 아래의 그림과 같이 각 단어 벡터에 가중치 행렬을 곱해 구할 수 있다. 아래의 그림은 간략하게 그렸지만 논문에서는 $d_{model}=512$ 차원을 가진 각 단어 벡터들이 64차원의 Q, K, V 벡터로 변환되었다. 여기서 64는 $d_{model}=512$을 num\\_heads=8로 나눈 것이다. (num_heads는 뒤에서 나올 Multi Head Attention에서 나올 하이퍼파라미터이다.)\n",
    "\n",
    "- Q, K, V의 차원: $d_{model}$/ num\\_heads \n",
    "- 가중치 행렬의 크기: $d_{model}$ x $d_{model}$/num\\_heads\n",
    "  (가중치 행렬은 훈련 과정 중 학습된다.)\n",
    "![](https://images.velog.io/images/guide333/post/d2f4c481-aa5e-4f05-af4d-1d14ee9fe472/Screenshot%20from%202021-03-09%2020-39-33.png)\n",
    "\n",
    "### Scaled Dot Product Attention\n",
    "어텐션 값을 구하는 수식은 아래와 같다. \n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/deb3aafd-c292-496b-b685-ff4f7f0ed6bc/Screenshot%20from%202021-03-04%2011-57-46.png)\n",
    "\n",
    "- Q, K, V는 단어 벡터를 행으로 하는 문장 행렬이다.\n",
    "- 벡터의 내적(dot product)은 벡터의 유사도를 의미한다.\n",
    "- 값의 크기를 조절하는 스케일링을 한다. \n",
    "\n",
    "수식을 그림으로 표현하면 아래와 같다. \n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/1643056d-18d8-4671-bf1d-99a6097317d0/Screenshot%20from%202021-03-04%2012-00-19.png)\n",
    "\n",
    "초록색 행렬은 각 단어 벡터의 유사도가 모두 기록된 __유사도 행렬__($QK^T$)이다. 이 유사도 값을 스케일링해주려고 행렬 전체를 특정 값($\\sqrt{d_k}$)으로 나눠준다. (논문에서 $d_k=d_{model}$/num_heads=64이므로 $\\sqrt{d_k}$는 8이다.) 그 후 소프트맥스 함수를 사용하여 어텐션 분포를 구하고, 각 어텐션 분포에서 나온 값에 문장 행렬 V를 곱하면 어텐션 값이 나온다. (노드에서는 정규화를 해주려고 소프트맥스 함수를 사용한다고 나온다.)\n",
    "\n",
    "위의 수식은 내적을 통해 단어 벡터 같 유사도를 구한 후 특정 값을 분모로 나눠주는 방식으로 Q와 K의 유사도를 구하였다고 해서 스케일드 닷 프로덕트 어텐션이라고 한다. \n",
    "\n",
    "- 행렬의 크기 \n",
    "1. $d_k$: Q, K 벡터의 크기 -> Q, K 행렬의 크기: (seq\\_len, $d_k$), V 행렬의 크기: (seq_len, $d_v$) \n",
    "2. $W^Q, W^K$의 크기: ($d_{model}, d_k$), $W^V$의 크기: ($d_{model}, d_v$)(문장행렬과 Q, K, V행렬의 크기로부터 추정)\n",
    "3. $d_k=d_v=d_{model}$/num\\_heads이므로 어텐션 값 행렬 a의 크기는 (seq\\_len, $d_v$)이다. \n",
    "\n",
    "### Multi-Head Attention\n",
    "어텐션을 병렬로 수행하는 것을 멀티 헤드 어텐션이라고 한다. 트랜스포머는 입력된 문장 행렬을 num\\_heads의 수만큼 쪼개 어텐션을 수행하고 어텐션의 값 행렬 num\\_heads개를 하나로 연결(concatenate)한다. 연결된 어텐션 헤드 행렬의 크기는 (seq\\_len, $d_{model}$)이다.\n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/50ac269d-fd1f-4d9c-ac47-3d60626cc077/Screenshot%20from%202021-03-04%2012-07-00.png)\n",
    "\n",
    "병렬로 수행되는 어텐션은 서로 다른 시각에서의 셀프 어텐션 결과를 얻기 때문에 각각 다른 관점에서의 정보를 얻을 수 있어서 효과가 더 좋다. \n",
    "![](https://images.velog.io/images/guide333/post/145034e0-9d28-49b0-931c-41ce470aeb21/Screenshot%20from%202021-03-09%2021-08-10.png)\n",
    "\n",
    "어텐션 헤드를 모두 연결한 행렬에 가중치 행렬 $W^O$를 곱해 나온 결과 행렬이 멀티 헤드 어텐션의 결과물이며, 이 행렬의 크기는 (seq\\_len, $d_{model}$)이다. \n",
    "\n",
    "여기서 가중치 행렬을 곱하는 것을 구현 상에서는 입력을 밀집층(Dense layer)를 지나게 하여 구현한다. \n",
    "\n",
    "### Masking\n",
    "#### 1. Padding Masking\n",
    " 패딩토큰을 이용한 마스킹을 패딩 마스킹이라고 한다. 자연어 처리에서 정해준 길이보다 짧은 문장에 숫자 0을 채워서 문장의 길이를 맞춰주는 전처리 작업을 한다. 여기서 숫자 0은 실제 의미가 있는 단어가 아니므로 어텐션 등과 같은 연산에서 제외하기 위해 패딩 마스킹을 한다.\n",
    " \n",
    "scaled_dot_product_attention() 함수에서 ```logits += (mask * -1e9)```이 패딩 마스킹의 역할을 한다. 즉 어텐션 스코어 행렬의 마스킹 위치에 매우 작은 음수값을 넣어준다. 소프트맥스 함수를 지나면 해당 위치의 값은 0에 가까운 값이 되어 패딩 토큰이 단어 간 유사도를 구하는데 반영되지 않는다. \n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/fba8e8fe-b191-4654-b40c-89ae178cc057/Screenshot%20from%202021-03-09%2021-18-27.png)\n",
    "\n",
    "#### 2. Look-ahead masking(다음 단어 가리기)\n",
    "룩어헤드 마스킹은 디코더의 셀프 어텐션에서 사용된다. 인코더와 달리 디코더에서는 뒤의 단어를 미리 알게 되면 다음 단어를 예측하는 훈련을 할 수 없기 때문에 자신보다 다음에 나올 단어를 참고하지 않도록 가려준다. 즉 쿼리 단어 뒤에 나오는 키 단어들에 대해서 마스킹하여 이전 단어들과의 유사도만 구하게 한다. 아래의 그림에서 빨간색 부분이 마스킹한 부분이다.\n",
    "![](https://images.velog.io/images/guide333/post/0d992e3a-da5a-4516-8bcb-498e203ae779/Screenshot%20from%202021-03-09%2022-45-55.png)\n",
    "\n",
    "룩어헤드 마스크에는 패딩 마스크를 포함하도록 구현한다. \n",
    "\n",
    "### Position-wise FFNN 포지션-와이즈 피드 포워드 신경망\n",
    "포지션 와이즈 FFNN(Fully-connected FFNN)의 수식과 식을 그림으로 표현한 것은 아래와 같다. \n",
    "\n",
    "$$FFNN(x) = MAX(0, xW_1+b_1)W_2 + b_2$$\n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/5fc68984-22cb-4556-9835-9c8d281ee7ae/Screenshot%20from%202021-03-09%2021-31-15.png)\n",
    "\n",
    "- x: 멀티 헤드 어텐션의 결과로 나온 (seq\\_len, $d_{model}$)의 크기를 가지는 행렬\n",
    "- 가중치 행렬 $W_1$: ($d_{model}, d_{ff}$)의 크기를 가진다.\n",
    "- 가중치 행렬 $W_2$: ($d_{ff}, d_{model}$)의 크기를 가진다. ($d_{ff}$는 은닉층의 크기)\n",
    "\n",
    "매개변수 $W_1, b_1, W_2, b_2$은 하나의 인코더 층에서는 동일하나 인코더 층마다는 다른 값을 가진다. \n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/5cc9e463-89b1-4e4e-ae9d-22e773682c32/Screenshot%20from%202021-03-09%2021-33-34.png)\n",
    "\n",
    "### Residual connection 잔차 연결, Layer Normalization 층 정규화\n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/daa47032-4692-44ce-ade1-90f263c86bb0/Screenshot%20from%202021-03-09%2021-35-33.png)\n",
    "\n",
    "#### 1. 잔차 연결\n",
    "![](https://images.velog.io/images/guide333/post/380a32c4-dff1-4b41-a4c6-73085fe4fafc/Screenshot%20from%202021-03-09%2021-36-17.png)\n",
    "\n",
    "함수 $F(x)$는 트랜스포머에서의 서브층을 의미한다. 잔차연결은 서브층의 입력과 출력을 더하는 것이다. 만약 서브층이 멀티 헤드 어텐션이면 잔차 연결 연산은 아래와 같다.  \n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/0ebdf378-c152-4a47-81f8-6fc071960957/Screenshot%20from%202021-03-09%2021-37-34.png)\n",
    "\n",
    "#### 2. 층 정규화\n",
    "$$LN = LayerNorm(x + Sublayer(x))$$ \n",
    "\n",
    "층 정규화는 __텐서의 마지막 차원__ 에 대해 평균과 분산을 구한 값으로 정규화하여 학습을 돕는다. 텐서의 마지막 차원은 $d_{model}$ 차원이며, 아래 그림은 $d_{model}$ 차원의 방향을 화살표로 표현하였다. 출력의 크기는 (seq\\_len, $d_{model}$)이다. 화살표 방향으로 평균과 분산을 구하고, 정규화를 해준다. 층 정규화를 한 후에 벡터 $x_i$는 $ln_i$라는 벡터로 정규화된다. \n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/7a50b2c8-8c78-4287-bfab-3415678cfff1/Screenshot%20from%202021-03-09%2022-27-57.png)\n",
    "\n",
    "$$ln_i=LayerNorm(x_i)$$\n",
    "\n",
    "층 정규화는 2가지 과정으로 이루어진다. \n",
    "\n",
    "1. 평균과 분산을 통해 벡터 $x_i$를 정규화한다.\n",
    "$$\\hat x_{i,k} = \\frac {x_{i,k}-\\mu_i}{\\sqrt{{\\sigma_i}^2 + \\epsilon}}$$ \n",
    "(여기서 $\\epsilon$은 분모가 0이 되는 것을 방지하는 값)\n",
    "\n",
    "2. 감마와 베타라는 벡터를 준비해 아래와 같이 정규화를 해준다. (감마와 베타의 초기값은 각각 1과 0이다.)\n",
    "![](https://images.velog.io/images/guide333/post/2fee9051-c08b-406b-9d3e-63eb0cb25e81/Screenshot%20from%202021-03-09%2022-34-18.png)\n",
    "$$ln_i = \\gamma \\hat x_i + \\beta = LayerNorm(x_i)$$  ($\\gamma, \\beta$는 학습 가능한 파라미터)\n",
    "\n",
    "### 디코더에서의 어텐션\n",
    "디코더에는 두 개의 멀티 헤드 어텐션이 들어간다. 첫번째 서브층은 mask의 인자값으로 look_ahead_mask가 들어가고, 두번째 서브층은 mask의 인자값으로 padding_mask가 들어간다. \n",
    "\n",
    "## 트랜스포머 구현\n",
    "인코더와 디코더를 각각 구현하고, 인코더와 디코더를 각각 원하는 개수만큼 쌓아준다. 인코더를 먼저 쌓고 마지막 인코더에서의 출력값을 디코더로 전달해준다. 디코더를 쌓은 후 마지막에 다중 클래스 분류 문제를 풀 수 있도록 vocab_size만큼의 뉴련을 가지는 신경망을 추가한다. \n",
    "\n",
    "## 트랜스포머 하이퍼파라미터 \n",
    "- 단어 집합의 크기 vocab\\_size\n",
    "- 룩업 테이블을 수행할 임베딩 테이블과 포지셔널 인코딩의 행렬의 행의 크기 num\\_layers\n",
    "- 포지션 와이즈 피드 포워드 신경망의 은닉층 $d_{ff}$\n",
    "- 인코더와 디코더의 입/출력 차원 $d_{model}$\n",
    "- 멀티-헤드 어텐션의 헤드 수 num\\_heads\n",
    "\n",
    "## 손실함수\n",
    "다중 클래스 분류 문제이므로 크로스 엔트로피 함수를 손실함수로 사용한다.\n",
    "\n",
    "## 학습률 learning rate\n",
    "학습 경과에 따라 학습률이 변하도록 설계하였다. 아래는 공식이며 warmup\\_step은 4,000이다. \n",
    "\n",
    "$ Irate = d_{model}^{-0.5} x min(step_min^{-0.5}, step_num x warmup_steps^{-1.5}$\n",
    "\n",
    "위의 수식은 $step\\_num^{−0.5}$에 비례하는 부분과 $step\\_num$에 비례하는 부분 중 작은 쪽을 택하도록 되어 있어서 학습 초기에는 learning_rate가 $step\\_num$에 비례해서 증가하다가 이후로는 감소한다. \n",
    "\n",
    "이처럼 학습 초기에 학습률을 급격히 높였다가 이후 학습이 진행되면서 서서히 낮추어 가면서 안정적으로 수렴하게 하는 고급 기법을 널리 사용하는 방법을 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)이라고 한다. \n",
    "\n",
    "## 순서\n",
    "1. 데이터 수집하기\n",
    "2. 데이터 전처리하기\n",
    "3. SubwordTextEncoder 사용하기\n",
    "4. 모델 구성하기\n",
    "5. 모델 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-brunei",
   "metadata": {},
   "source": [
    "### Step 1. 데이터 수집하기\n",
    "한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용한다.\n",
    "\n",
    "```python\n",
    "$ wget https://github.com/songys/Chatbot_data/raw/master/ChatbotData%20.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "magnetic-jones",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Duplicate key in file PosixPath('/home/aiffel-dj44/Downloads/aiffel/envs/aiffel/lib/python3.7/site-packages/matplotlib/mpl-data/matplotlibrc'), line 253 ('font.family:  sans-serif')\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 불러오기 \n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "threatened-vietnamese",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\", filename=\"ChatBotData.csv\")\n",
    "chatbot_data = pd.read_csv('ChatBotData.csv')\n",
    "chatbot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "african-india",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇 샘플의 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "print('챗봇 샘플의 개수: {}'.format(len(chatbot_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-topic",
   "metadata": {},
   "source": [
    "질문과 답변의 쌍으로 이루어진 데이터셋이고, 챗봇 샘플의 개수는 11,823개이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "distributed-venture",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(chatbot_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "material-occurrence",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                         12시 땡!\n",
      "1                    1지망 학교 떨어졌어\n",
      "2                   3박4일 놀러가고 싶다\n",
      "3                3박4일 정도 놀러가고 싶다\n",
      "4                        PPL 심하네\n",
      "                  ...           \n",
      "11818             훔쳐보는 것도 눈치 보임.\n",
      "11819             훔쳐보는 것도 눈치 보임.\n",
      "11820                흑기사 해주는 짝남.\n",
      "11821    힘든 연애 좋은 연애라는게 무슨 차이일까?\n",
      "11822                 힘들어서 결혼할까봐\n",
      "Name: Q, Length: 11823, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(chatbot_data['Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "female-printing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                      하루가 또 가네요.\n",
      "1                       위로해 드립니다.\n",
      "2                     여행은 언제나 좋죠.\n",
      "3                     여행은 언제나 좋죠.\n",
      "4                      눈살이 찌푸려지죠.\n",
      "                   ...           \n",
      "11818          티가 나니까 눈치가 보이는 거죠!\n",
      "11819               훔쳐보는 거 티나나봐요.\n",
      "11820                      설렜겠어요.\n",
      "11821    잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
      "11822          도피성 결혼은 하지 않길 바라요.\n",
      "Name: A, Length: 11823, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(chatbot_data['A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-flooring",
   "metadata": {},
   "source": [
    "### Step 2. 데이터 전처리하기\n",
    "정규표현식을 이용하여 구두점을 단어들과 분리시켜 단어와 구두점 사이에 공백을 추가한다. 이로써 단어를 토크나이징하는 과정에서 구두점과 붙어 있는 단어를 하나의 단어로 인식하는 것을 방지할 수 있다.\n",
    "\n",
    "영어 데이터와 다르게 한국어 데이터는 대문자, 소문자 개념이 없으므로 노드에서의 소문자 변환 부분은 제거하였다. 단어와 구두점 사이에 거리를 만들고 문장 중간이나 양 옆에 빈 곳이 있다면 다 없애 버렸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "linear-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for sentence in chatbot_data['Q']:\n",
    "    # 단어와 구두점 사이에 거리를 만든다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dependent-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for sentence in chatbot_data['A']:\n",
    "    # 단어와 구두점 사이에 거리를 만든다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "measured-modern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lyric-lodge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 11823\n",
      "전체 샘플수 : 11823\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플수 :', len(questions))\n",
    "print('전체 샘플수 :', len(answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-williams",
   "metadata": {},
   "source": [
    "데이터를 학습데이터와 평가데이터로 나누어 결과를 확인한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "favorite-election",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions: 10640\n",
      "answers: 10640\n",
      "test_Q: 1183\n",
      "test_A: 1183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "questions, test_Q, answers, test_A = train_test_split(questions, \n",
    "                                                      answers, \n",
    "                                                      test_size=0.1,  \n",
    "                                                      shuffle=True)\n",
    "\n",
    "print(\"questions:\", len(questions)) \n",
    "print(\"answers:\", len(answers))\n",
    "print(\"test_Q:\", len(test_Q)) \n",
    "print(\"test_A:\", len(test_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-morris",
   "metadata": {},
   "source": [
    "### Step 3. SubwordTextEncoder 사용하기\n",
    "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 하지만 여기서는 형태소 분석기가 아닌 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용한다. 그 과정은 다음과 같다. \n",
    "\n",
    "1. TensorFlow Datasets __SubwordTextEncoder를 토크나이저__ 로 사용한다.  단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고,  각 토큰을 고유한 __정수로 인코딩__ 한다.\n",
    "2. 각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는 START_TOKEN 및 END_TOKEN을 추가한다.\n",
    "3. 최대 길이 __MAX_LENGTH__ 인 40을 넘는 문장들은 필터링한다.\n",
    "4. MAX_LENGTH보다 길이가 짧은 문장들은 40에 맞도록 패딩한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-uzbekistan",
   "metadata": {},
   "source": [
    "#### 1. 단어장 만들기\n",
    "각 단어에 고유한 정수 인덱스를 부여하기 위해 단어장을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "italic-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변 데이터셋에 대한 vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "genuine-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "greenhouse-gross",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [7600]\n",
      "END_TOKEN의 번호 : [7601]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :', [tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :', [tokenizer.vocab_size+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-cover",
   "metadata": {},
   "source": [
    "현재 단어장의 크기가 7,599이라는 의미이다. 2개의 토큰을 추가했으므로 단어장의 크기도 +2임을 명시한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prepared-thickness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7602\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-highland",
   "metadata": {},
   "source": [
    "#### 2. 각 단어를 고유한 정수로 인코딩 & 패딩\n",
    "tensorflow_datasets의 SubwordTextEncoder를 사용해서 tokenizer를 정의하고 Vocabulary를 만들었다면, tokenizer.encode()로 각 단어를 정수로 변환할 수 있고 또는 tokenizer.decode()를 통해 정수 시퀀스를 단어 시퀀스로 변환할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "committed-gateway",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [107, 168, 2808, 2478, 660]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [6, 6710, 10, 43, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업 수행, 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "architectural-sunday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)\n",
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "native-france",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기: 7602\n",
      "필터링 후의 질문 샘플 개수: 10640\n",
      "필터링 후의 답변 샘플 개수: 10640\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기: {}'. format(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(questions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fixed-adjustment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7600  425   13  112   13  777   13  937 7601    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "opponent-duncan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7600  359 1667   34  261    1 7601    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-logan",
   "metadata": {},
   "source": [
    "### Step 4. 모델 구성하기\n",
    "위 실습 내용을 참고하여 트랜스포머 모델을 구현한다. \n",
    "\n",
    "- 미리 구현해야 할 레이어\n",
    "1. Positional Encoding\n",
    "2. Attention(scaled dot product attention)\n",
    "3. Multi-head Attention\n",
    "4. Padding masking\n",
    "5. Look ahead masking\n",
    "\n",
    "- 인코더\n",
    "1. Input\n",
    "2. Padding mask\n",
    "3. Multi-head Attention(self-attention)\n",
    "4. Dropout + Residual connection + Layer Normalization\n",
    "5. Position-wise FFNN\n",
    "6. Dropout + Residual connection + Layer Normalization\n",
    "\n",
    "- 인코더 쌓기\n",
    "\n",
    "- 디코더\n",
    "1. Look-ahead mask\n",
    "2. Padding mask\n",
    "3. Multi-head Attention(masked self attention)\n",
    "4. Residual connection + Layer Normalization\n",
    "5. Multi-head Attention(encoder-decoder attention)\n",
    "6. Dropout + Residual connection + Layer Normalization\n",
    "7. Position-wise FFNN\n",
    "8. Dropout + Residual connection + Layer Normalization\n",
    "\n",
    "- 디코더 쌓기\n",
    "\n",
    "- 트랜스포머 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ancient-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "        # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-punch",
   "metadata": {},
   "source": [
    "- tf.pow(x, y) : Given a tensor x and a tensor y, this operation computes $x^y$ for corresponding elements in x and y.\n",
    "- tf.dtypes.cast(x, tf.int32): The operation casts x (in case of Tensor) or x.values (in case of SparseTensor or IndexedSlices) to dtype.\n",
    "- tf.range(limit, delta=1, dtype=None, name='range')      \n",
    "tf.range(start, limit, delta=1, dtype=None, name='range')      \n",
    "Creates a sequence of numbers that begins at start and extends by increments of delta up to but not including limit.\n",
    "\n",
    "The dtype of the resulting tensor is inferred from the inputs unless it is provided explicitly.\n",
    "\n",
    "Like the Python builtin range, start defaults to 0, so that range(n) = range(0, n).\n",
    "\n",
    "```python\n",
    "start = 3\n",
    "limit = 18\n",
    "delta = 3\n",
    "tf.range(start, limit, delta)\n",
    "\n",
    "# <tf.Tensor: shape=(5, ), dtype=int32, numpy=array([3,6,9,12,15], dtype=int32)>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "stone-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  \"\"\"어텐션 가중치를 계산. \"\"\"\n",
    "  # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "  # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "  # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "  # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "  # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 스케일링\n",
    "  # dk의 루트값으로 나눠준다.\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "  # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "  # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "distributed-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    # d_model을 num_heads로 나눈 값.\n",
    "    # 논문 기준 : 64\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    # WO에 해당하는 밀집층 정의\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # linear layers(가중치 행렬곱)\n",
    "    # q : (batch_size, query의 문장 길이, d_model)\n",
    "    # k : (batch_size, key의 문장 길이, d_model)\n",
    "    # v : (batch_size, value의 문장 길이, d_model)\n",
    "    # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
    "    # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "    # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "    # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 헤드 연결(concatenate)하기\n",
    "    # (batch_size, query의 문장 길이, d_model)\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # final linear layer(가중치 행렬곱)\n",
    "    # (batch_size, query의 문장 길이, d_model)\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fatty-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 마스킹 구현 함수\n",
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "associate-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 룩어헤드 마스킹 함수 구현\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-overall",
   "metadata": {},
   "source": [
    "- tf.linalg.band_part(\n",
    "    input, num_lower, num_upper, name=None\n",
    ")\n",
    ": Copy a tensor setting everything outside a central band in each innermost matrix to zero.\n",
    "\n",
    "- t f.ones(\n",
    "    shape, dtype=tf.dtypes.float32, name=None\n",
    ")\n",
    ": Creates a tensor with all elements set to one (1).\n",
    "\n",
    "- tf.math.maximum(\n",
    "    x, y, name=None\n",
    "):\n",
    "Returns the max of x and y (i.e. x > y ? x : y) element-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "alleged-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재\n",
    "\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs, \n",
    "          'key': inputs, \n",
    "          'value': inputs, # Q = K = V\n",
    "          'mask': padding_mask # 패딩 마스크 사용\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층): 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "mechanical-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 쌓기\n",
    "def encoder(vocab_size, \n",
    "            num_layers, \n",
    "            units,\n",
    "            d_model, \n",
    "            num_heads, \n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 인코더는 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  # 포지셔널 인코딩 \n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  # 드롭아웃\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model, \n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout, \n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "stainless-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재\n",
    "\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "  # 룩어헤드 마스크(첫번째 서브레이어)\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "  # 패딩 마스크(두번째 서브레이어)\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs, \n",
    "          'key': inputs, \n",
    "          'value': inputs, # Q = K = V\n",
    "          'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1, \n",
    "          'key': enc_outputs, \n",
    "          'value': enc_outputs, # Q != K = V\n",
    "          'mask': padding_mask # 패딩 마스크\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "biological-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 쌓기\n",
    "def decoder(vocab_size, \n",
    "            num_layers, \n",
    "            units,\n",
    "            d_model, \n",
    "            num_heads, \n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "    \n",
    "  # 패딩 마스크  \n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩 \n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # 디코더를 num_layers개 쌓기\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(units=units, d_model=d_model, num_heads=num_heads,\n",
    "        dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "normal-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교사 강요\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "experienced-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머 구현\n",
    "def transformer(vocab_size, \n",
    "                num_layers, \n",
    "                units,\n",
    "                d_model, \n",
    "                num_heads, \n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "\n",
    "  # 인코더의 입력\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 디코더의 입력\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask, \n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size, \n",
    "      num_layers=num_layers, \n",
    "      units=units,\n",
    "      d_model=d_model, \n",
    "      num_heads=num_heads, \n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "  # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size, \n",
    "      num_layers=num_layers, \n",
    "      units=units,\n",
    "      d_model=d_model, \n",
    "      num_heads=num_heads, \n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층(다음 단어 예측을 위한 출력층0)\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "southwest-kansas",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 (None, None, 256)    3527424     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, None, 256)    4318464     dec_inputs[0][0]                 \n",
      "                                                                 encoder[1][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 7602)   1953714     decoder[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,799,602\n",
      "Trainable params: 9,799,602\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 3 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "million-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수\n",
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "turkish-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습률\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "gorgeous-inside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습률 시각화\n",
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "constant-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dated-request",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "167/167 [==============================] - 12s 70ms/step - loss: 1.4670 - accuracy: 0.0204\n",
      "Epoch 2/20\n",
      "167/167 [==============================] - 12s 69ms/step - loss: 1.2221 - accuracy: 0.0469\n",
      "Epoch 3/20\n",
      "167/167 [==============================] - 11s 69ms/step - loss: 1.0412 - accuracy: 0.0502\n",
      "Epoch 4/20\n",
      "167/167 [==============================] - 12s 70ms/step - loss: 0.9636 - accuracy: 0.0532\n",
      "Epoch 5/20\n",
      "167/167 [==============================] - 11s 68ms/step - loss: 0.9123 - accuracy: 0.0561\n",
      "Epoch 6/20\n",
      "167/167 [==============================] - 11s 68ms/step - loss: 0.8631 - accuracy: 0.0588\n",
      "Epoch 7/20\n",
      "167/167 [==============================] - 12s 70ms/step - loss: 0.8086 - accuracy: 0.0627\n",
      "Epoch 8/20\n",
      "167/167 [==============================] - 11s 68ms/step - loss: 0.7483 - accuracy: 0.0682\n",
      "Epoch 9/20\n",
      "167/167 [==============================] - 12s 69ms/step - loss: 0.6817 - accuracy: 0.0754\n",
      "Epoch 10/20\n",
      "167/167 [==============================] - 11s 68ms/step - loss: 0.6116 - accuracy: 0.0832\n",
      "Epoch 11/20\n",
      "167/167 [==============================] - 12s 71ms/step - loss: 0.5386 - accuracy: 0.0919\n",
      "Epoch 12/20\n",
      "167/167 [==============================] - 11s 68ms/step - loss: 0.4649 - accuracy: 0.10070s - los\n",
      "Epoch 13/20\n",
      "167/167 [==============================] - 11s 69ms/step - loss: 0.3935 - accuracy: 0.1103\n",
      "Epoch 14/20\n",
      "167/167 [==============================] - 11s 68ms/step - loss: 0.3252 - accuracy: 0.1196\n",
      "Epoch 15/20\n",
      "167/167 [==============================] - 11s 68ms/step - loss: 0.2626 - accuracy: 0.1288\n",
      "Epoch 16/20\n",
      "167/167 [==============================] - 12s 72ms/step - loss: 0.2083 - accuracy: 0.1371\n",
      "Epoch 17/20\n",
      "167/167 [==============================] - 13s 78ms/step - loss: 0.1610 - accuracy: 0.1453\n",
      "Epoch 18/20\n",
      "167/167 [==============================] - 12s 69ms/step - loss: 0.1243 - accuracy: 0.1517\n",
      "Epoch 19/20\n",
      "167/167 [==============================] - 11s 68ms/step - loss: 0.0970 - accuracy: 0.1565\n",
      "Epoch 20/20\n",
      "167/167 [==============================] - 11s 68ms/step - loss: 0.0791 - accuracy: 0.1598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8fd4052190>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련\n",
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-strain",
   "metadata": {},
   "source": [
    "Loss가 점차 떨어지는 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-sunday",
   "metadata": {},
   "source": [
    "### Step 5. 모델 평가하기\n",
    "Step 1에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수를 만든다.\n",
    "\n",
    "예측 단계는 다음의 과정을 거친다.\n",
    "1. 새로운 입력 문장에 대해서 훈련 때와 동일한 전처리를 거친다.\n",
    "2. 입력 문장을 토크나이징하고 START_TOKEN과 END_TOKEN을 추가한다.\n",
    "3. 패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
    "4. 디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
    "5. 디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
    "6. END_TOKEN이 예측되거나 문장의 최대길이에 도달하면 디코더는 동작을 멈춘다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "little-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없으므로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측 반복\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됨\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-basket",
   "metadata": {},
   "source": [
    "노드에서는 preprocess_sentence() 함수를 데이터 전처리할 때 사용하였지만 이 프로젝트에서는 사용하지 않아 여기서 preprocess_sentence() 함수를 사용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fewer-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만든다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만든다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-sitting",
   "metadata": {},
   "source": [
    "임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 sentence_generation() 함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adopted-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받는다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "married-stability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 12시 땡!\n",
      "출력 : 하루가 또 가네요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'하루가 또 가네요 .'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('12시 땡!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "veterinary-appendix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : PPL 심하네\n",
      "출력 : 눈살이 찌푸려지죠 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'눈살이 찌푸려지죠 .'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"PPL 심하네\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "restricted-hearing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 졸려\n",
      "출력 : 오늘 일찍 주무세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'오늘 일찍 주무세요 .'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"졸려\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "similar-health",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 인간은 같은 잘못을 반복하고\n",
      "출력 : 너무 안맞는다는 것이 아니라 정신적으로 괴로워으로 괴로워 나이가 타납니다 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'너무 안맞는다는 것이 아니라 정신적으로 괴로워으로 괴로워 나이가 타납니다 .'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"인간은 같은 잘못을 반복하고\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "becoming-taylor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 쉬고 싶어\n",
      "출력 : 내려 놓으세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'내려 놓으세요 .'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"쉬고 싶어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "resident-distribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 저녁은 뭐 먹을까?\n",
      "출력 : 맛있는 거 드세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'맛있는 거 드세요 .'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"오늘 저녁은 뭐 먹을까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "municipal-sleeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 오해했네 그리고 차단 ㅎㅎ\n",
      "대답: 차단하는게 서로에게 좋을 때가 있어요 .\n",
      "--------------------\n",
      "질문: 정신과 방금다녀와서 처방전 받고 왔어 .\n",
      "대답: 마음도 편하고 후련하고 기분이 좋아질 거예요 .\n",
      "--------------------\n",
      "질문: 그림 좀 잘 그렸으면 좋겠다\n",
      "대답: 학원을 다니거나 연습하면 잘할 수 있을 거예요 .\n",
      "--------------------\n",
      "질문: 미세먼지 지수 뭐야 ?\n",
      "대답: 인터넷 검색 해보세요 .\n",
      "--------------------\n",
      "질문: 나 노트북 사줘\n",
      "대답: 노트북은 비싸요 .\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('질문: {}'.format(test_Q[i]))\n",
    "    print('대답: {}'.format(test_A[i]))\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-reminder",
   "metadata": {},
   "source": [
    "## 결과 정리\n",
    "인코더, 디코더를 2개로 쌓을 때보다 3개를 쌓았을 때 더 좋은 결과가 나왔다. 질문에 대한 대답이 어이 없는 것은 있지만 대부분 아예 연관 없는 대답은 아니라서 좋게 결과가 나온 것 같다. 하이퍼파라미터를 더 크게 잡고 에포크를 더 많이 돌린다면 더 좋은 결과가 나올 것 같다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-certification",
   "metadata": {},
   "source": [
    "## 루브릭\n",
    "|평가문항|\t상세기준|결과|\n",
    "|:------:|:--------:|:---:|\n",
    "|1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.|공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.|Y     |\n",
    "|2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.|구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.|Y   |\n",
    "|3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.|한국어 입력문장에 그럴듯한 한국어로 답변을 리턴하였다.| Y    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-improvement",
   "metadata": {},
   "source": [
    "## 후기\n",
    "### 이번 프로젝트에서 어려웠던 점\n",
    "- 트랜스포머의 구조를 이해하는 것이 어려웠다. 여러 번 동영상을 보고 LMS와 위키독스를 보면서 정리해서 조금은 이해할 것 같다. \n",
    "- 코드는 대체로 무난했지만 가끔 이해가 안 되는 부분이 있었다.\n",
    "\n",
    "### 프로젝트를 진행하면서 알게된 점\n",
    "- 트랜스포머의 구조와 각 레이어의 기능을 알게 되었다.\n",
    "\n",
    "### 프로젝트를 진행하면서 아직 모호한 점\n",
    "- 데이터 전처리 부분은 아직 잘 모르겠다. \n",
    "\n",
    "### 자기 다짐\n",
    "이번 프로젝트는 이론에 조금 더 치중하여 공부하였다. 이해가 안 되는 부분은 반복해서 보고 나서야 조금 이해할 수 있었다. 하지만 아직 데이터 전처리 부분은 이해가 잘 안 되기 때문에 시간을 내서 따로 공부해봐야할 것 같다. 지금까지 여러 번 자연어처리를 하였지만 그 부분을 대충 본 것이 후회된다. 어떻게 하면 전처리 부분을 효율적으로 할 수 있을지 고민해봐야겠다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
