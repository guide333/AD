{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incorporate-instruction",
   "metadata": {},
   "source": [
    "# 뉴스 카테고리 다중분류 \n",
    "\n",
    "## 노드 정리 \n",
    "\n",
    "### 머신러닝을 이용한 텍스트 분류\n",
    "#### 텍스트 분류(Text Classification)       \n",
    "주어진 텍스트를 사전 정의된 클래스(Pre-defined Class)들로 분류하는 자연어 처리 태스크. 자연어 처리 태스크 중 가장 기본이면서 비지니스 영역에서도 가장 수요가 높다.\n",
    "\n",
    "- 텍스트 분류의 영역    \n",
    "스팸 메일 자동 분류, 감성 분류(리뷰의 긍정, 부정 판단), 뉴스 카테고리 분류 등 \n",
    "\n",
    "- 텍스트 분류의 과정   \n",
    "\n",
    "![](https://images.velog.io/images/guide333/post/ff879870-2023-4881-9421-a336ea392e04/Screenshot%20from%202021-04-09%2009-39-34.png)\n",
    "\n",
    "설명: 주어진 문장/문서의 __벡터화__ -> AI 모델에 입력 -> 예측한 카테고리 리턴 \n",
    "\n",
    "벡터화 방법으로는 __워드 임베딩__ 을 사용하고, RNN, CNN, BERT 등의 딥러닝 모델을 사용해 클래스를 예측한다. \n",
    "\n",
    "텍스트 분류는 RNN의 다-대-일 문제이다. 텍스트 분류는 모든 시점에 대해 입력을 받지만 최종 시점의 RNN셀만 은닉 상태를 출력하고 이것이 출력층으로 가서 활성화 함수를 통해 정답을 고르는 문제이다. \n",
    "\n",
    "- 텍스트 분류의 종류     \n",
    "  - 클래스가 2개인 이진 분류(Binary Classification) - 스팸 메일 자동 분류, 감성분류, 출력층의 활성화 함수는 시그모이드 함수, 손실함수로 binary_crossentropy를 사용한다. \n",
    "  - 클래스가 3개 이상인 다중 클래스 분류(Multiclass Classification) - 뉴스 카테고리 분류, 출력층의 활성화함수로 소프트맥스 함수, 손실함수로 categorical_crossentropy를 사용한다. 클래스가 N개라면 출력층의 뉴런의 수도 N개이다. \n",
    "  \n",
    "### 로이터 뉴스 데이터 \n",
    "자연어 처리에서는 텍스트를 수치화하는 과정이 필요하나 텐서플로우 데이터셋에서는 이미 토큰화와 정수 인코딩(각 단어를 정수로 변환)가 되어 있어 데이터를 출력하면 숫자 시퀀스가 나온다. 또한 데이터에 단어들이 몇 번 등장하는 지의 빈도에 따라 인덱스를 부여하였다. \n",
    "\n",
    "### num_words\n",
    "데이터에서 빈도수를 기준으로 상위 몇 번째 단위까지 사용할 것인지를 조절한다. 각 단어에 고유 번호가 정해져 있고 이를 통해 사용할 단어의 수를 정한다. 데이터의 단어는 등장 빈도수가 높을수록 낮은 정수가 맵핑되어 있다. 즉 1번이면 제일 빈도수가 높은 단어이다. 여기서는 빈도수가 높은 단어만 사용한다. 여기서 1-10000번 단어보다 더 낮은 빈도수의 단어는 사라지는 것이 아니라 특정 번호로 맵핑되고, 이는 OOV문제를 야기할 수 있다.\n",
    "\n",
    "\n",
    "### 벡터화\n",
    "벡터화는 Word Embedding, Document Embedding, Contextual Embedding 등의 인공 신경망을 사용하거나 Bag of Words 가설을 기반으로 하는 DTM, TF-IDF 행렬 등과 같은 머신러닝을 사용하는 방법이 있다. \n",
    "\n",
    "### 머신러닝 모델\n",
    "[[GD-P2] 머신러닝 모델 정리](https://velog.io/@guide333/GD-P2-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-%EC%A0%95%EB%A6%AC) 참고\n",
    "\n",
    "### 분류성능평가지표\n",
    "- True Positive(TP) : 실제 True인 정답을 True라고 예측 (정답)\n",
    "- False Positive(FP) : 실제 False인 정답을 True라고 예측 (오답)\n",
    "- False Negative(FN) : 실제 True인 정답을 False라고 예측 (오답)\n",
    "- True Negative(TN) : 실제 False인 정답을 False라고 예측 (정답)\n",
    "\n",
    "- Precision    \n",
    "모델이 True라고 분류한 것 중 실제 True인 것의 비율. Positive 정답률\n",
    "\n",
    "$(Precision) = \\frac {TP}{TP + FP}$\n",
    "\n",
    "- Recall    \n",
    "실제 True인 것 중 모델이 True라고 예측한 것의 비율. sensitivity, hit rate.\n",
    "\n",
    "$(Precision) = \\frac {TP}{TP + FN}$\n",
    "\n",
    "Precision과 Recall은 trade-off 관계이고 두 지표가 높을수록 좋은 모델이다. \n",
    "\n",
    "- Accuracy    \n",
    "True를 True로, False를 False로 옳게 예측한 경우. 가장 직관적으로 모델의 성능을 나타내는 평가 지표. 그러나 data의 domain이 불균형하면 예측 성능이 낮아진다. \n",
    "\n",
    "$(Accuracy) = \\frac {TP + TN}{TP + FN + FP + TN}$\n",
    "\n",
    "- F1 Score     \n",
    "Precision과 Recall의 조화 평균. 데이터 label이 불균형할 때 모델의 성능을 정확히 평가할 수 있고 성능을 하나의 숫자로 표현한다.  \n",
    "\n",
    "$(F1-score) = 2 x \\frac {Precision x Recall}{Precision + Recall}$\n",
    "\n",
    "사이킷런의 metrics 패키지에서는 정밀도, 재현율, F1점수를 구하는 classification_report() 함수를 제공한다. 이 함수는 각각의 클래스를 양성(positive) 클래스로 보았을 때의 정밀도, 재현율, F1점수를 각각 구하고 그 평균값으로 전체 모델의 성능을 평가한다.\n",
    "## 프로젝트 순서\n",
    "1. Vocabulary Size를 변경해서 다양한 머신러닝 모델의 정확도 확인        \n",
    "  1) 모든 단어 사용      \n",
    "  2) 빈도수 상위 5,000개의 단어만 사용      \n",
    "  3) 직접 단어 갯수를 설정해서 사용        \n",
    "2. 딥러닝 모델과 비교해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-blank",
   "metadata": {},
   "source": [
    "## 4-9. 프로젝트: Vocabulary Size를 변경해서 시도해보기\n",
    "지금까지는 모델을 변경하고, 모델을 조합해서 성능을 올리는 일에 힘썼습니다. 그런데 어쩌면 성능을 높이는 방법은 단순히 모델을 조정하는 일이 한정되지 않을 수 있습니다. 데이터의 전처리는 모델의 성능에 영향을 직접적으로 줍니다. 특히나 Bag of Words를 기반으로 하는 DTM이나 TF-IDF의 경우, 사용하는 단어의 수를 어떻게 결정하느냐에 따라서 성능에 영향을 줄 수 있겠죠.\n",
    "\n",
    "중요도가 낮은 단어들까지 포함해서 너무 많은 단어를 사용하는 경우에도 성능이 저하될 수 있고, 반대로 너무 적은 단어들을 사용해도 성능이 저하될 수 있습니다. 그리고 이렇게 변화된 단어의 수는 또 어떤 모델을 사용하느냐에 따라 유리할 수도, 불리할 수도 있습니다.\n",
    "\n",
    "단어의 수에 따라서 모델의 성능이 어떻게 변하는지 테스트해 봅시다.\n",
    "\n",
    "```python\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)\n",
    "```\n",
    "\n",
    "앞서 ```num_words```로 사용할 단어의 수를 조정할 수 있다는 것을 배웠습니다. 빈도수가 많은 순서대로 나열했을 때, ```num_words```의 인자로 준 정숫값만큼의 단어를 사용하고 나머지 단어는 전부 ```<unk>```로 처리하는 원리였었죠.\n",
    "\n",
    "아래의 두 가지 경우에 대해서 지금까지 사용했던 모델들의 정확도를 직접 확인해 보세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "second-singapore",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:11:08.638682Z",
     "start_time": "2021-04-21T06:11:06.352716Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-poison",
   "metadata": {},
   "source": [
    "### 1. 모든 단어 사용\n",
    "\n",
    "```python\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imposed-synthetic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:11:09.213337Z",
     "start_time": "2021-04-21T06:11:08.639976Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "centered-syntax",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:11:10.007441Z",
     "start_time": "2021-04-21T06:11:10.004242Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수:8982\n",
      "테스트 샘플의 수:2246\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 샘플의 수:{}\".format(len(x_train)))\n",
    "print(\"테스트 샘플의 수:{}\".format(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "strategic-husband",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:11:10.674627Z",
     "start_time": "2021-04-21T06:11:10.671395Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 27595, 28842, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "----------------------------------------------------------------------\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 18292, 159, 9, 1084, 363, 13, 19231, 71, 9, 16273, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 16273, 7, 748, 48, 9, 19231, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 23406, 28185, 5, 192, 510, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(\"-\" * 70)\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-configuration",
   "metadata": {},
   "source": [
    "로이터 뉴스 데이터는 이미 전처리를 마친 후의 데이터이므로 숫자 인코딩이 되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "infinite-lotus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:11:16.314688Z",
     "start_time": "2021-04-21T06:11:16.312101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "injured-justice",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:11:19.652518Z",
     "start_time": "2021-04-21T06:11:19.649059Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스의 수: 46\n"
     ]
    }
   ],
   "source": [
    "# 클래스의 수 보기\n",
    "num_classes = max(y_train) + 1\n",
    "print(\"클래스의 수: {}\".format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tough-palace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:11:20.837045Z",
     "start_time": "2021-04-21T06:11:20.590055Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 뉴스의 최대 길이: 2376\n",
      "훈련용 뉴스의 평균 길이: 145.5398574927633\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYpklEQVR4nO3df7RdZX3n8fcHHUwoLSVyIZofxgJai0iFSC3VRimCwoC/RtshUEFXQZdoKwtLyoxTO2VRFVRcOmhjRcoIRnHUqChtReIUaMVg/VEsNXUWSBoIl6C0SFAq3/lj7yuH605yT3LPPTfnvl9rnZWzn/3sfb77rJv7vc+P/exUFZIkTbbHsAOQJM1OJghJUicThCSpkwlCktTJBCFJ6vTYYQcwXfbbb79atmzZsMOQpN3KzTfffE9VjXXtG5kEsWzZMtavXz/sMCRpt5Lk9m3tG2iCSPIy4CDgCOAPaLq0TgO2ABuq6tq23jnARmBxVV3Ulh0DHAiMAZdW1aZBxipJerSBJYgkPw98r6o+meQk4CXAM4E3VtWDSS5Lch3wQmBjVa1JsjLJccAXgZVVdXqS+cDFwJmDilWS9LMGNkhdVf9eVRN9PocC/xdYUFUPtmUbgMOBk4Dr2rJ1wInAs4Bb2/NsBcaSZFCxSpJ+1kBnMSXZM8m7gIOBe4D7e3bfCTwJWASMt2V3AUva1+aeuvcDCzrOf0aS9UnWj4+PT94tSdoFA00QVfXjqjob+BJNF1Hvwk8FpH31lneVTdSdfP7VVbW8qpaPjXUOwkuSdtKM3AdRVZfTtCL26SleCNwObKIZiAbYH7iDZsD6gJ66e9MMbEuSZsiMJIgkjwe+DdzXDjpDM7vpZuBq4Oi2bAWwFriJZtyCJPOAzeWys5I0owY5i2kpcCXwUeAB4N00LYRzk9wNXFlVDwNrk5yX5BRgYVWtaY+/IslZwL7A+YOKU5LULaPyh/ny5cvLG+UkqT9Jbq6q5V37RuZO6kFZturqzvLb3nbCDEciSTPLxfokSZ1MEJKkTiYISVInE4QkqZMJQpLUyQQhSepkgpAkdTJBSJI6mSAkSZ1MEJKkTiYISVInE4QkqZMJQpLUyQQhSepkgpAkdTJBSJI6mSAkSZ1MEJKkTiYISVInE4QkqZMJQpLUyQQhSepkgpAkdTJBSJI6mSAkSZ0eO8iTJzkT2A9YCpxXVVuSrAYeAB4G3lxVP0lyDrARWFxVF7XHHgMcCIwBl1bVpkHGKkl6tIEliCTPBq6vqluSHAy8Psk1wJVVta6n3vHAxqpak2RlkuOALwIrq+r0JPOBi4EzBxWrJOlnDbKL6TtVdUv7fhxYAKwAzkyyqv3FD3AScF37fh1wIvAs4FaAqtoKjCXJAGOVJE0ysARRVff2bL4S+GxVXQicDNwHfLDdt4gmgQDcBSxpX5t7jr+fJsE8SpIzkqxPsn58fHzybknSLhj4IHWSMeCoqroWoBrvB5Yk2RMIUL2HdJRVW/YoVbW6qpZX1fKxsbGBXYMkzUUDTRBtt9A7gFUdu++g+cW/iWYgGmD/tnwjcEBP3b2BLYOLVJI02aBbEGcDH6mqu5L8tIsoyR40A9MPAVcDR7e7VgBrgZuAQ9u684DNVVVIkmbMIGcxHQ2cBqxN8nzgcUmOAG4AbgcuBKiqtUnOS3IKsLCq1rTHX5HkLGBf4PxBxSlJ6jawBFFVX6JtBUyh7gUdZddMe1CSpCnzTmpJUicThCSpkwlCktTJBCFJ6mSCkCR1MkFIkjqZICRJnUwQkqROJghJUqeBPlFud7Fs1dXDDkGSZh1bEJKkTiYISVInE4QkqZMJQpLUyQQhSepkgpAkdTJBSJI6mSAkSZ1MEJKkTiYISVInE4QkqZMJQpLUyQQhSeo05QSR5LeSHJBkaZJ3JnnuIAOTJA1XPy2IJ1fVZuAD7WvhYEKSJM0G/SSIJHkjcE1VbQCeNKCYJEmzQD8PDPoIcFBVfSvJQYBP2ZGkEdZPgjgRWAR8C9gCHLyjA5KcCewHLAXOA+YBp7XHb6iqa9t65wAbgcVVdVFbdgxwIDAGXFpVm/qIVZK0i/pJEI8DvgtQVd9PcjJw07YqJ3k2cH1V3ZLkYOD1wGLgjVX1YJLLklwHvBDYWFVrkqxMchzwRWBlVZ2eZD5wMXDmzlygJGnn9DMGcf/EmyS/wI7HIL5TVbe078dpWhILqurBtmwDcDhwEnBdW7aOpqXyLOBWgKraCowlSR+xSpJ2UT8J4lvAkUk+ALyXpstom6rq3p7NVwI30JNkgDtpkswimgQCcBewpH1t7ql7P7Bg8mckOSPJ+iTrx8fHJ++WJO2CKSeIqvqXqvrvVfXaqnoVj/5lv01JxoCjaFoJ1XtKIO2rt7yrbKLu5JhWV9Xyqlo+NjY21UuRJE3BdscgklwJPNi1i6Yb6Ok7OD7AO4BVNAPT+/TsXgj8I7CJZiD6bmB/4A6aAevn9NTduz1ekjRDdjRIfW5V3dG1I8khUzj/2cBHququJAuA+5LMb8cVDgLeDjwROBpYA6wA1tIMfr+u/Zx5wOaqqq4PkCQNxnYTRG9yaAemXws8Abi2qj63vWOTHE0zpXVtkucDewJ/DJyb5G7gyqp6uN1/XpJTgIVVtaY9/ookZwH7Aufv7AVKknZOP9Nc3wtcAnwdOCTJK6rqqm1VrqovAYd27HprR90LOsqu6SM2SdI062cW061V9ZWq+lFVfQ34EUASV4SVpBHUzy/3f0/yS+1qrkuB32j/PWNAsUmShqifLqYjaG52mxgsfgA4HXgmzequkqQR0k+C+L2q+o+JjSTz2iUz9htAXJKkIesnQfxKkuNpZiMFeAbw8qq6ZyCRSZKGqp8EcQHwh8AP2+3nbKeuJGk310+C+HRVfXtiI4ktB0kaYf0kiB8l+TNgK00X02HAywYSlSRp6PpJEK8AzqWZvQR2MUnSSOsnQXyiqv5pYqNdLkOSNKL6SRBHJnk6zTLfP53FNJCoJElD10+C+Gvgmzxyo9xvTn84kqTZYsoJoqo+07ud5MvTH44kabaYcoJol+M+emKT5hGgLx5EUJKk4euni+nXaZ4HsQK4FjhhIBFJkmaFflZzvb6qfgw8TPPo0MMGE5IkaTboJ0F8KcnLqupa4A19HitJ2s30M0i9Gfhku/kZ4NvbqS5J2s1NuRWQ5B1J9k/yNpr7H143uLAkScPWTzfRV4H5wNKqeguwaTAhSZJmg34SxB3A7wJvSHIwzUC1JGlE9TMG8ffA37ebW4ANA4lIkjQrOBNJktRpuwkiyQEzFYgkaXbZUQviTybeJPnPvTuSPH4gEUmSZoUdjUFckuR3adZeekGSBW15aFZzfc0gg5MkDc92E0RVfTPJd4BfA24Fbu/ZfcSOTp5kD+BU4PNVNd6WraZ5Kt3DwJur6idJzgE2Aour6qK23jHAgcAYcGlVOa1WkmbQDmcxVdWDwJfbF0nmV9XWJDdM4fxH0dxU92VgPMmRwJVVtW6iQpLjgY1VtSbJyiTHAV8EVlbV6UnmAxcDZ/Z3aZKkXdHPndTLk3wG+FCSvwR+ZUfHVNX1wNd6ilYAZyZZ1f7iBzgJuK59vw44EXgWTYuFqtoKjCXJVGOVJO26fqa5Lq+qk6rq5Kp6Fc0jR/tSVRcCJwP3AR9sixcB4+37u4Al7Wtzz6H30zx/4lGSnJFkfZL14+Pjk3dLknZBPwni/03avm9nPrAa7weWJNmTZsC7eqqko6zassnnWl1Vy6tq+djY2M6EI0nahn4SxFOTrEiyJMlLmEIX0w7cQfOLfxPNQDTA/m35RqD3Hoy9ae7eliTNkH4SxCXAk4E/BPYDLtzZD21nN22sqoeAq3nkUaYrgLXATcChbd15wOaqqq5zSZIGo5+1mH4CXNa+piTJITS//B9K8j7gU8ANNNNlL2zPuzbJee0zrxdW1Zr22CuSnAXsC5w/1c+UJE2Pfp5J3bequoXmhroJR2+j3gUdZdcMKi5J0o65WJ8kqVM/90GsGmQgkqTZpZ8WxKPuQ0hy6DTHIkmaRfoZg1iQ5G9opqEGeBrw7IFEJUkaun4SxGXt0hkAJOkccJYkjYZ+uph+kOSlAEl+EfingUQkSZoV+kkQxwJ7AVTVD4CzBhGQJGl26KeL6V8mbT9lOgORJM0u/SSIe4GVSZbTrMP00cGEJEmaDfpZauN64Pok+wH3VtXDgwtLkjRsU04QSY4Ffh/4HnBbksur6s6BRSZJGqp+uphOBU6caDkkeSXw8YFEJUkaun5mMd04qVtp63QHI0maPbbZgkhyBHBCT9FBSZ5M8/jPx9AsvfHZwYYnSRqW7XUxfZ1mqe5PduybB/zcIAKSJM0O20wQ7QOC3r2t/UkOHkhEkqRZoZ9ZTG8FDgQeolms71eBZw4kKknS0PUzi2mfqjp1YiPJ4gHEI0maJfqZxfTlJOnZ/vnpDkaSNHv004I4BnhVku/TdDE9k6abSZI0gvpJEA9U1UsnNuxikqTR1k8X098meUzP9l7THYwkafbopwVxBnBykq04i0mSRl4/CeI1VXX3xEaSpQOIZ7exbNXVneW3ve2EznJJ2t1MKUEk2QN4WpJf7ik+HLh4EEFJkoZvSgmiqh5OcjJwY1u0D/ALA4tKkjR0/XQxvb6q/mNiI8mrBxCPJGmW6KeL6TeSVFs0H3gZcOkUjjsV+HxVjSdZBJwGbAE2VNW1bb1zgI3A4qq6qC07hmZpjzHg0qra1Oe1SZJ2wZSmubbPgfgvwJPb1/7A2VM49Cjg5Tyy8usfA++sqg8ApybZI8nxwMaqWgPcmeS4djrtyqr6c+Cd7XGSpBnUzzOp39C7nWRsCsdc37YEJloTC6rqwXb3BpqB7pN4JAGsA/4IuA+4tT3H1iRjSVJVhSRpRvSzmuuJwItongUR4BnAEX181uNpHjY04U7gScAiYLwtuwtY0r4299S9n+YBRVsmxXQGzf0ZLF06p2fdStK062eQ+hXA6e1zIkhydJ+fFaC3BVBt2eTyrrKJuo9SVauB1QDLly+3dSFJ06ifpTa+MJEcWt/s87O20EyPnbAQuB3YRDMQDc3Yxh00A9YH9NTdm0mtB0nSYPWTIF6Y5GNJLk3yYeAL/XxQm1zuSzK/LToIuBm4GphojawA1gI3AYcCJJkHbHb8QZJmVj9dTJdU1VcmNpL81o4OSHIIzS//h5K8l2Yw+twkdwNXtrOj1iY5L8kpwMJ2NhNJrkhyFrAvcH4fcUqSpkE/s5i+Mmn72ikccwvwmz1F/wa8taPeBR1l10w1NknS9Ouni0mSNIeYICRJnUwQkqROJghJUicThCSpkwlCktSpn/sgNAU+ilTSqLAFIUnqZIKQJHUyQUiSOpkgJEmdTBCSpE4mCElSJxOEJKmTCUKS1MkEIUnqZIKQJHUyQUiSOpkgJEmdTBCSpE4mCElSJxOEJKmTCUKS1MkEIUnqZIKQJHUyQUiSOg3lmdRJDgPeBPwA+CqwDjgN2AJsqKpr23rnABuBxVV10TBilaS5aigJAngBcHpVFUCS1cAbq+rBJJcluQ54IbCxqtYkWZnkuKr6qyHFK0lzzox3MSUJsAK4PMmxSfYAFlTVg22VDcDhwEnAdW3ZOuDEmY5VkuayGW9BtK2GE5M8HvjfwD7A/T1V7gSeBCwCxtuyu4Alk8+V5AzgDIClS5cOMGpJmnuG1cVEVW1J8ibg3cDm3l1A2lf1lKfjHKuB1QDLly+vyftnk2Wrru4sv+1tJ8xwJJI0NcOexXQHTXLYp6dsIXA7sAkYa8v2b+tKkmbIsBPEkcBVwH1J5rdlBwE3A1cDR7dlK4C1Mx+eJM1dM97FlOT5wFuAjwH3VtVVSf4RODfJ3cCVVfUwsDbJeUlOARZW1ZqZjlWS5rJhDFJfxyOzkybKvge8taPuBTMUliRpkmF3MUmSZikThCSpkwlCktTJBCFJ6mSCkCR1MkFIkjoNbakNNVyCQ9JsZQtCktTJBCFJ6mSCkCR1MkFIkjqZICRJnZzFNEs5u0nSsNmCkCR1MkFIkjqZICRJnUwQkqROJghJUidnMe1mnN0kaabYgpAkdTJBSJI62cU04uySkrSzTBAjYluJQJJ2ll1MkqROtiDmKLueJO2ICUJTsr0uLJOKNJpMEHqU6RzLsJUi7d5mdYJI8tvAPGAZ8M6qun+4EamLA+TSaJq1CSLJAuCoqvr9JIuA89qXdnP9JhRbHNJwzNoEARwL3AhQVf+a5GlDjkdDYkKRhmM2J4glwFd7tvecXCHJGcAZ7eb9Sf55Jz5nP+CenThuVIzc9eftfR8yct9Bn7z+uX39T9rWjtmcIALU9ipU1Wpg9S59SLK+qpbvyjl2Z3P9+sHvwOuf29e/PbP5RrmNwAE92z8eViCSNBfN5gTxN8BzAZI8Afj2cMORpLll1nYxVdV4kq8keQ2wGPizAX3ULnVRjYC5fv3gd+D1q1OqttvNL0mao2ZzF5MkaYhMEJKkTrN2DGImzKWlPJIcBrwJ+AHN/SXrgNOALcCGqrq2rXcOzQyyxVV10TBinS5J9gBOBT7fjmktYorXnOQY4EBgDLi0qjYN4RJ22eTvoC1bDTwAPAy8uap+MqrfQZIzae5zWEqzEsM85tjPwC6pqjn5AhYA72nfLwIuGHZMA77ec2jHnNrt1cC89v1lNK3J44HfactWAscNO+5dvObnAJ8BlvVzzcBjgA+3ZfOBPx/2tUzjd3Ak8LxJdUbyOwCeDRzSvj8Y+B9z8WdgV15zuYvpUUt5ACO7lEeSACuAy5Mc2/5VuaCqHmyrbAAOB04CrmvL1gEnznSs06mqrge+Bj/9S3qq1/ws4Nb2HFuBsfY73O30fgetFcCZSVYlmd+Wjep38J2quqV9P07TkphzPwO7Yi4niCXA5p7tn1nKY1RU40TgD9rXy4He7rQ7aW63X0TzHwngLprvaFQ8nqlf8+SfjftpWpy7vaq6EDgZuA/4YFs8kt9BVd3bs/lK4Ab8GejLXE4QO1zKY9RU1RaacYjTefS1F833Mfk7GaW/mCZf2/aueVt1R0L7B8P7gSVJ9mTEv4MkY8BRNK0Efwb6MJcTxFxdyuMOmr+M9ukpWwjcDmyiGZAD2L+tOyq2MPVrnvyzsXd7/Ki5g+YX38h+B2230DuAVfgz0Le5nCDm6lIeRwJXAff19EEfBNwMXA0c3ZatANbOfHiDUVU/YerXfBNwKECSecDmakcrR0U7JrOxqh5itL+Ds4GPVNVdNMnBn4E+zOk7qZOcAjyOZimPkZ3mmuT5wFuAjwH3VtVVSZYCrwbuBv65Hpnudx7wPWBh7f7TXA8B3g/8FfBe4BeZ4jUneSHNL5B9gQ/VbjrFcdJ38D7gUzR98bcDn2q7HUfyO0hyNPAeHvlDZ0+a72BO/QzsijmdICRJ2zaXu5gkSdthgpAkdTJBSJI6mSAkSZ1MEJKkTiYIjZQkv5rkf03zOQ/blXMmOSHJB6Yzph183vFJ/ttMfZ5GlwlCI6Wqvg783DSf8xs7e84kvwbcWVWvnc6YduDbwH+awc/TiDJBSB3aVsOKaTjVi4B7d1hLmoXm9AODNNqSHE5zl/wTaZZ2vh14O7CGZkmFW6vqfUl+D/g3mhU8Xwy8Fng98OMki6vqCmCvJK+neVbAu6pq3aTPeiLwUuC7NEs0/CXwIPAM4NVJPl1VX+up/2Kah9csraoL2wc6HQa8BHhLVd2S5AKa9X9+BLwMeFt7vhe09fYBPgx8lGa5+sdV1dmT4nouzSqkBwF/TbP20tPb17sn7qSWupggNMpOBb5Ms6zCQVV1bZKqqquAq5JMLHf9UppnADwMHNj+cr4RuK0nEewLXAJ8HPhTmucG9HoLcE5V/TDJN4Dzq+qMJN8ELquq2ybVPxZ4M48sHvfUqro8yWZgOXALTVIbr6rPJXkYeExVXZRkK/DMqroxyb1VdTlAkj9qu7Q2t9uheQDONe138BSaZHkD8Dnm4Oqk6o8JQqNsr6r69KSy3vW2JvrpzwfeAHwH+J/bONe/tou1jbeLt022pKp+CFBVd7Ytiu35C+CzwIeAK4HPJzmBpiVwT1uneuJ9ANjavv8hjzy/5KGec/4DTQKYeI7BGE2C+fREhSR7Ae9qj3/dDmLUHOcYhEbZfkkeC5Bkew97+a9VdXFVfb6q7mzLiv7+f9ybZP+ez/ruDur/kKa76rfb7T+l+Uv/H/r4zMmeDPxdz/YW4JCJjTauxe2A+Y00j9qUtskWhEZKkucBT28fEvMe4BNJvgv8RftX/XOSLKOZlfTcJL8E/F2Sj9MMJt9J89zibwBvTvIQTVfMU9tzPhV4SpIDqqr3iWOrgNck+RawFPiTJAuB5wHfT3JJu7T2hN9pP+ML7fYTaMY9tgDPT/J/gF8HFiX5W5rnKy/tef9Emm6usSRvoHmGwa1VdVeS02gemTkf+GiST9B0V70POKzthppH09UkbZOruWrOS7KKZlD5HprnAhxUVdN6L8WgJLmsqk4bdhwaTXYxSU0L4UU0XT570cwMmvWS/DJweJLnDDsWjSZbENJuLu3UrGHHodFjgpAkdbKLSZLUyQQhSepkgpAkdTJBSJI6/X+KK1+j5GA1AgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"훈련용 뉴스의 최대 길이: {}\".format(max(len(l) for l in x_train)))\n",
    "print(\"훈련용 뉴스의 평균 길이: {}\".format(sum(map(len, x_train))/len(x_train)))\n",
    "      \n",
    "plt.hist([len(s) for s in x_train], bins=50)\n",
    "plt.xlabel(\"length of samples\")\n",
    "plt.ylabel(\"number of samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "general-superior",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:11:24.311119Z",
     "start_time": "2021-04-21T06:11:23.932164Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 클래스의 분포 보기\n",
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(12, 5)\n",
    "sns.countplot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "parliamentary-bolivia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:11:25.223802Z",
     "start_time": "2021-04-21T06:11:25.220666Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 클래스 빈도수:\n",
      "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
      "    42   43   44   45]\n",
      " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
      "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
      "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
      "    13   21   12   18]]\n"
     ]
    }
   ],
   "source": [
    "# 수치로 확인\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"각 클래스 빈도수:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "russian-exercise",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:11:41.412246Z",
     "start_time": "2021-04-21T06:11:41.409088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 55, 1: 432, 2: 74, 3: 3159, 4: 1949, 5: 17, 6: 48, 7: 16, 8: 139, 9: 101, 10: 124, 11: 390, 12: 49, 13: 172, 14: 26, 15: 20, 16: 444, 17: 39, 18: 66, 19: 549, 20: 269, 21: 100, 22: 15, 23: 41, 24: 62, 25: 92, 26: 24, 27: 15, 28: 48, 29: 19, 30: 45, 31: 39, 32: 32, 33: 11, 34: 50, 35: 10, 36: 49, 37: 19, 38: 19, 39: 24, 40: 36, 41: 30, 42: 13, 43: 21, 44: 12, 45: 18}\n"
     ]
    }
   ],
   "source": [
    "# 위와 같은 코드\n",
    "label_cnt = dict(zip(unique_elements, counts_elements))\n",
    "print(label_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-yukon",
   "metadata": {},
   "source": [
    "### 데이터 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "mature-looking",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:13:02.290904Z",
     "start_time": "2021-04-21T06:13:02.276529Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터의 단어장\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "# reuters.get_word_index에는 실제 단어에 매핑한 정수에 -3을 해주었으므로 +3을 해준다.\n",
    "index_to_word = {index + 3: word for word, index in word_index.items()}\n",
    "\n",
    "# <pad>:0, <sos>:1, <unk>:2 토큰 넣어주기\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "honey-essex",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:14:03.932164Z",
     "start_time": "2021-04-21T06:14:03.930413Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "piano-planning",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:14:39.659491Z",
     "start_time": "2021-04-21T06:14:39.657608Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "radio-asian",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T06:14:04.096609Z",
     "start_time": "2021-04-21T06:14:03.945007Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 뉴스 데이터를 텍스트 데이터로 변환(훈련, 테스트)\n",
    "\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "serial-furniture",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:03:10.576224Z",
     "start_time": "2021-04-11T13:03:10.537584Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "weekly-baker",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:03:10.580339Z",
     "start_time": "2021-04-11T13:03:10.577442Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> mcgrath rentcorp said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dressed-perspective",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:03:10.584290Z",
     "start_time": "2021-04-11T13:03:10.581551Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> the great atlantic and pacific tea co said its three year 345 mln dlr capital program will be be substantially increased to accommodate growth and expansion plans for waldbaum inc and shopwell inc over the next two years a and p said the acquisition of shopwell in august 1986 and waldbaum in december helped us achieve better than expected results in the fourth quarter ended february 28 its net income from continuing operations jumped 52 6 pct to 20 7 mln dlrs or 55 cts a share in the latest quarter as sales increased 48 3 pct to 1 58 billion dlrs a and p gave no details on the expanded capital program but it did say it completed the first year of the program during 1986 a and p is 52 4 pct owned by lt tengelmann warenhandelsgesellschaft of west germany reuter 3'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-stupid",
   "metadata": {},
   "source": [
    "### 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "facial-master",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:03:10.716174Z",
     "start_time": "2021-04-11T13:03:10.585869Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "polyphonic-english",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:03:11.498822Z",
     "start_time": "2021-04-11T13:03:10.717194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 26506)\n"
     ]
    }
   ],
   "source": [
    "# DTM 만들기\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pediatric-yemen",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:03:11.553564Z",
     "start_time": "2021-04-11T13:03:11.500238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 26506)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF 행렬 만들기\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "essential-emperor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:03:11.752029Z",
     "start_time": "2021-04-11T13:03:11.555059Z"
    }
   },
   "outputs": [],
   "source": [
    "# 평가 데이터를 TF-IDF로 변환\n",
    "x_test_dtm = dtmvector.transform(x_test)  # DTM 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm)  # DTM -> TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-homework",
   "metadata": {},
   "source": [
    "## 머신러닝 모델 사용하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "falling-latino",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:03:11.799948Z",
     "start_time": "2021-04-11T13:03:11.753310Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score #정확도 계산\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "resistant-idaho",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:03:11.811162Z",
     "start_time": "2021-04-11T13:03:11.801119Z"
    }
   },
   "outputs": [],
   "source": [
    "def models_accuracy(tfidfv, tfidfv_test, y_train, y_test):\n",
    "    # 나이브 베이즈 분류기\n",
    "    \n",
    "    mod = MultinomialNB()\n",
    "    mod.fit(tfidfv, y_train)\n",
    "    \n",
    "    predicted = mod.predict(tfidfv_test)\n",
    "    print(\"나이브 베이즈 정확도:\", accuracy_score(y_test, predicted))\n",
    "    print(\"나이브 베이즈 f1 score:\", f1_score(y_test, predicted, average='weighted'))\n",
    "    \n",
    " \n",
    "    # Complement Naive Bayes Classifier(CNB)\n",
    "    cb = ComplementNB()\n",
    "    cb.fit(tfidfv, y_train)\n",
    "    \n",
    "    predicted = cb.predict(tfidfv_test)\n",
    "    print(\"CMB 정확도:\", accuracy_score(y_test, predicted))\n",
    "    print(\"CMB f1 score:\", f1_score(y_test, predicted, average='weighted'))\n",
    "    \n",
    "    # 로지스틱 회귀(Logistic Regression)\n",
    "    lr = LogisticRegression(C=10000, penalty='l2')\n",
    "    lr.fit(tfidfv, y_train)\n",
    "    \n",
    "    predicted = lr.predict(tfidfv_test)\n",
    "    print(\"로지스틱 회귀 정확도:\", accuracy_score(y_test, predicted))\n",
    "    print(\"로지스틱 회귀 f1 score:\", f1_score(y_test, predicted, average='weighted'))\n",
    "    \n",
    "    # 선형 서포트 벡터 머신(SVM)\n",
    "    lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "    lsvc.fit(tfidfv, y_train)\n",
    "    \n",
    "    predicted = lsvc.predict(tfidfv_test)\n",
    "    print(\"SVM 정확도:\", accuracy_score(y_test, predicted))\n",
    "    print(\"SVM f1 score:\", f1_score(y_test, predicted, average='weighted'))\n",
    "    \n",
    "    # Decision Tree\n",
    "    tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "    tree.fit(tfidfv, y_train)\n",
    "    \n",
    "    predicted = tree.predict(tfidfv_test)\n",
    "    print(\"Decision Tree 정확도:\", accuracy_score(y_test, predicted))\n",
    "    print(\"Decision Tree f1 score:\", f1_score(y_test, predicted, average='weighted'))\n",
    "    \n",
    "    # 랜덤 포레스트\n",
    "    forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "    forest.fit(tfidfv, y_train)\n",
    "    \n",
    "    predicted = forest.predict(tfidfv_test)\n",
    "    print(\"랜덤 포레스트 정확도:\", accuracy_score(y_test, predicted))\n",
    "    print(\"랜덤 포레스트 f1 score:\", f1_score(y_test, predicted, average='weighted'))\n",
    "    \n",
    "    # 그래디언트 부스팅 트리\n",
    "    grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "    grbt.fit(tfidfv, y_train)  # 시간이 오래 걸림(10분 넘음)\n",
    "    \n",
    "    predicted = grbt.predict(tfidfv_test)\n",
    "    print(\"그래디언트 부스팅 트리 정확도:\", accuracy_score(y_test, predicted))\n",
    "    print(\"그래디언트 부스팅 트리 f1 score:\", f1_score(y_test, predicted, average='weighted'))\n",
    "    \n",
    "    # 보팅\n",
    "    voting_classifier = VotingClassifier(estimators=[\n",
    "          ('lr', LogisticRegression(C=10000, penalty='l2')),\n",
    "          ('cb', ComplementNB()),\n",
    "          ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "    ], voting='soft', n_jobs=-1)\n",
    "    voting_classifier.fit(tfidfv, y_train)\n",
    "    \n",
    "    predicted = voting_classifier.predict(tfidfv_test)\n",
    "    print(\"보팅 정확도:\", accuracy_score(y_test, predicted))\n",
    "    print(\"보팅 f1 score:\", f1_score(y_test, predicted, average='weighted'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "meaning-klein",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:32:52.104059Z",
     "start_time": "2021-04-11T13:03:11.812697Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이브 베이즈 정확도: 0.5997328584149599\n",
      "나이브 베이즈 f1 score: 0.5045670886188423\n",
      "CMB 정확도: 0.7649154051647373\n",
      "CMB f1 score: 0.7346534179503126\n",
      "로지스틱 회귀 정확도: 0.813446126447017\n",
      "로지스틱 회귀 f1 score: 0.8079349566211766\n",
      "SVM 정확도: 0.7791629563668745\n",
      "SVM f1 score: 0.7735699243235148\n",
      "Decision Tree 정확도: 0.6211041852181657\n",
      "Decision Tree f1 score: 0.5769283128518846\n",
      "랜덤 포레스트 정확도: 0.6544968833481746\n",
      "랜덤 포레스트 f1 score: 0.6225909375608356\n",
      "그래디언트 부스팅 트리 정확도: 0.7702582368655387\n",
      "그래디언트 부스팅 트리 f1 score: 0.7641672650539437\n",
      "보팅 정확도: 0.8187889581478184\n",
      "보팅 f1 score: 0.8147231278247327\n"
     ]
    }
   ],
   "source": [
    "models_accuracy(tfidfv, tfidfv_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-watch",
   "metadata": {},
   "source": [
    "### 2. 빈도수 상위 5,000개의 단어만 사용\n",
    "\n",
    "```python\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "institutional-morris",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:22:35.555581Z",
     "start_time": "2021-04-11T14:22:35.001239Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "clear-stand",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:32:52.588702Z",
     "start_time": "2021-04-11T13:32:52.571329Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터의 단어장\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "# reuters.get_word_index에는 실제 단어에 매핑한 정수에 -3을 해주었으므로 +3을 해준다.\n",
    "index_to_word = {index + 3: word for word, index in word_index.items()}\n",
    "\n",
    "# <pad>:0, <sos>:1, <unk>:2 토큰 넣어주기\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "appreciated-arrangement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:32:52.719392Z",
     "start_time": "2021-04-11T13:32:52.589765Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 뉴스 데이터를 텍스트 데이터로 변환(훈련, 테스트)\n",
    "\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "encouraging-school",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:32:52.756837Z",
     "start_time": "2021-04-11T13:32:52.720547Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-confirmation",
   "metadata": {},
   "source": [
    "### 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "requested-juice",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:32:53.435260Z",
     "start_time": "2021-04-11T13:32:52.761191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 4867)\n"
     ]
    }
   ],
   "source": [
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "southern-drilling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:32:53.475813Z",
     "start_time": "2021-04-11T13:32:53.436399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 4867)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "collected-vulnerability",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:32:53.654972Z",
     "start_time": "2021-04-11T13:32:53.476918Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test_dtm = dtmvector.transform(x_test)  # DTM 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm)  # DTM -> TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "increased-tutorial",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:49:14.835142Z",
     "start_time": "2021-04-11T14:22:36.653465Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이브 베이즈 정확도: 0.6731967943009796\n",
      "나이브 베이즈 f1 score: 0.6012501291711391\n",
      "CMB 정확도: 0.7707034728406055\n",
      "CMB f1 score: 0.7458990404916549\n",
      "로지스틱 회귀 정확도: 0.8058771148708815\n",
      "로지스틱 회귀 f1 score: 0.7994583667437475\n",
      "SVM 정확도: 0.7680320569902048\n",
      "SVM f1 score: 0.7631712079535768\n",
      "Decision Tree 정확도: 0.6179875333926982\n",
      "Decision Tree f1 score: 0.5729970881280324\n",
      "랜덤 포레스트 정확도: 0.701246660730187\n",
      "랜덤 포레스트 f1 score: 0.6770217603524399\n",
      "그래디언트 부스팅 트리 정확도: 0.767586821015138\n",
      "그래디언트 부스팅 트리 f1 score: 0.7662475269931749\n",
      "보팅 정확도: 0.8161175422974176\n",
      "보팅 f1 score: 0.8126712904613167\n"
     ]
    }
   ],
   "source": [
    "models_accuracy(tfidfv, tfidfv_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-anthony",
   "metadata": {},
   "source": [
    "### 3. 직접 단어 갯수를 설정해서 사용\n",
    "위 단계에서 5000으로 제시된 ```num_words```를 다양하게 바꾸어 가며 성능을 확인해보세요. 변화된 단어 수에 따른 모델의 성능을 연구해 보세요. 최소 3가지 경우 이상을 실험해 보기를 권합니다.\n",
    "\n",
    ">사용할 모델\n",
    ">\n",
    ">나이브 베이즈 분류기, CNB, 로지스틱 회귀, 서포트 벡터 머신, 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 트리, 보팅\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-mathematics",
   "metadata": {},
   "source": [
    "#### 3000 개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "attempted-armstrong",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:58:38.131058Z",
     "start_time": "2021-04-11T13:58:37.700749Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=3000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "advised-stock",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:58:38.150262Z",
     "start_time": "2021-04-11T13:58:38.132352Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터의 단어장\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "# reuters.get_word_index에는 실제 단어에 매핑한 정수에 -3을 해주었으므로 +3을 해준다.\n",
    "index_to_word = {index + 3: word for word, index in word_index.items()}\n",
    "\n",
    "# <pad>:0, <sos>:1, <unk>:2 토큰 넣어주기\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "everyday-basket",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:58:38.270114Z",
     "start_time": "2021-04-11T13:58:38.151367Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 뉴스 데이터를 텍스트 데이터로 변환(훈련, 테스트)\n",
    "\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "entire-internet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:58:38.303970Z",
     "start_time": "2021-04-11T13:58:38.271422Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-beatles",
   "metadata": {},
   "source": [
    "### 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "european-algorithm",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:58:38.951412Z",
     "start_time": "2021-04-11T13:58:38.309236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 2919)\n"
     ]
    }
   ],
   "source": [
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "plain-wheel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:58:38.990145Z",
     "start_time": "2021-04-11T13:58:38.952825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 2919)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "excessive-python",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T13:58:39.159628Z",
     "start_time": "2021-04-11T13:58:38.991272Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test_dtm = dtmvector.transform(x_test)  # DTM 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm)  # DTM -> TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "unusual-baker",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:22:34.999524Z",
     "start_time": "2021-04-11T13:58:39.160814Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이브 베이즈 정확도: 0.6874443455031166\n",
      "나이브 베이즈 f1 score: 0.6266168450864102\n",
      "CMB 정확도: 0.7644701691896705\n",
      "CMB f1 score: 0.7369718160654114\n",
      "로지스틱 회귀 정확도: 0.794746215494212\n",
      "로지스틱 회귀 f1 score: 0.7898493631150233\n",
      "SVM 정확도: 0.744879786286732\n",
      "SVM f1 score: 0.7401980202704703\n",
      "Decision Tree 정확도: 0.6260017809439002\n",
      "Decision Tree f1 score: 0.580006731123168\n",
      "랜덤 포레스트 정확도: 0.6856634016028496\n",
      "랜덤 포레스트 f1 score: 0.6591675010462239\n",
      "그래디언트 부스팅 트리 정확도: 0.7756010685663401\n",
      "그래디언트 부스팅 트리 f1 score: 0.7720993479918031\n",
      "보팅 정확도: 0.8103294746215495\n",
      "보팅 f1 score: 0.8061827291048885\n"
     ]
    }
   ],
   "source": [
    "models_accuracy(tfidfv, tfidfv_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-ranking",
   "metadata": {},
   "source": [
    "#### 8000개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "indian-sandwich",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:22:35.555581Z",
     "start_time": "2021-04-11T14:22:35.001239Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=8000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "native-international",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:22:35.576425Z",
     "start_time": "2021-04-11T14:22:35.556810Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터의 단어장\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "# reuters.get_word_index에는 실제 단어에 매핑한 정수에 -3을 해주었으므로 +3을 해준다.\n",
    "index_to_word = {index + 3: word for word, index in word_index.items()}\n",
    "\n",
    "# <pad>:0, <sos>:1, <unk>:2 토큰 넣어주기\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "massive-pierce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:22:35.711715Z",
     "start_time": "2021-04-11T14:22:35.577617Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 뉴스 데이터를 텍스트 데이터로 변환(훈련, 테스트)\n",
    "\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "alleged-gasoline",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:22:35.747444Z",
     "start_time": "2021-04-11T14:22:35.712710Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-mechanism",
   "metadata": {},
   "source": [
    "### 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "joint-juice",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:22:36.429552Z",
     "start_time": "2021-04-11T14:22:35.751436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 7772)\n"
     ]
    }
   ],
   "source": [
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "frequent-saudi",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:22:36.472277Z",
     "start_time": "2021-04-11T14:22:36.430697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 7772)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "injured-thomson",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:22:36.652358Z",
     "start_time": "2021-04-11T14:22:36.473520Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test_dtm = dtmvector.transform(x_test)  # DTM 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm)  # DTM -> TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "surgical-possession",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:49:14.835142Z",
     "start_time": "2021-04-11T14:22:36.653465Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이브 베이즈 정확도: 0.6625111308993766\n",
      "나이브 베이즈 f1 score: 0.5832772940898228\n",
      "CMB 정확도: 0.7707034728406055\n",
      "CMB f1 score: 0.7468888117983166\n",
      "로지스틱 회귀 정확도: 0.8098842386464826\n",
      "로지스틱 회귀 f1 score: 0.8045664468720659\n",
      "SVM 정확도: 0.7764915405164737\n",
      "SVM f1 score: 0.7717867825345066\n",
      "Decision Tree 정확도: 0.6206589492430988\n",
      "Decision Tree f1 score: 0.5741562924518827\n",
      "랜덤 포레스트 정확도: 0.6669634906500446\n",
      "랜덤 포레스트 f1 score: 0.6386081274272609\n",
      "그래디언트 부스팅 트리 정확도: 0.7644701691896705\n",
      "그래디언트 부스팅 트리 f1 score: 0.7602265349360933\n",
      "보팅 정확도: 0.813446126447017\n",
      "보팅 f1 score: 0.8099987343995103\n"
     ]
    }
   ],
   "source": [
    "models_accuracy(tfidfv, tfidfv_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-reason",
   "metadata": {},
   "source": [
    "#### 10000개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "after-execution",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:49:15.372356Z",
     "start_time": "2021-04-11T14:49:14.836881Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "civilian-station",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:49:15.394446Z",
     "start_time": "2021-04-11T14:49:15.373586Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터의 단어장\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "# reuters.get_word_index에는 실제 단어에 매핑한 정수에 -3을 해주었으므로 +3을 해준다.\n",
    "index_to_word = {index + 3: word for word, index in word_index.items()}\n",
    "\n",
    "# <pad>:0, <sos>:1, <unk>:2 토큰 넣어주기\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "brilliant-struggle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:49:15.545574Z",
     "start_time": "2021-04-11T14:49:15.396339Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 뉴스 데이터를 텍스트 데이터로 변환(훈련, 테스트)\n",
    "\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "intermediate-texas",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:49:15.588533Z",
     "start_time": "2021-04-11T14:49:15.546765Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-eligibility",
   "metadata": {},
   "source": [
    "### 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "distributed-metallic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:49:16.286798Z",
     "start_time": "2021-04-11T14:49:15.592755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 9670)\n"
     ]
    }
   ],
   "source": [
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "greek-irish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:49:16.333698Z",
     "start_time": "2021-04-11T14:49:16.287853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 9670)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "minus-senegal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T14:49:16.516926Z",
     "start_time": "2021-04-11T14:49:16.334758Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test_dtm = dtmvector.transform(x_test)  # DTM 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm)  # DTM -> TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cardiovascular-candy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T15:10:06.962189Z",
     "start_time": "2021-04-11T14:49:16.517982Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이브 베이즈 정확도: 0.6567230632235085\n",
      "나이브 베이즈 f1 score: 0.5764467518778252\n",
      "CMB 정확도: 0.7707034728406055\n",
      "CMB f1 score: 0.7456682614453047\n",
      "로지스틱 회귀 정확도: 0.8076580587711487\n",
      "로지스틱 회귀 f1 score: 0.8014651882605348\n",
      "SVM 정확도: 0.7693677649154052\n",
      "SVM f1 score: 0.7637759765488678\n",
      "Decision Tree 정확도: 0.6202137132680321\n",
      "Decision Tree f1 score: 0.5776398779280149\n",
      "랜덤 포레스트 정확도: 0.674087266251113\n",
      "랜덤 포레스트 f1 score: 0.6429484177284822\n",
      "그래디언트 부스팅 트리 정확도: 0.7666963490650045\n",
      "그래디언트 부스팅 트리 f1 score: 0.7625990588567523\n",
      "보팅 정확도: 0.8116651825467498\n",
      "보팅 f1 score: 0.8082216149049796\n"
     ]
    }
   ],
   "source": [
    "models_accuracy(tfidfv, tfidfv_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-telescope",
   "metadata": {},
   "source": [
    "#### 15,000개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "statistical-leonard",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T15:10:07.377867Z",
     "start_time": "2021-04-11T15:10:06.963453Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=15000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "superior-logan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T15:10:07.398516Z",
     "start_time": "2021-04-11T15:10:07.379217Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터의 단어장\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "# reuters.get_word_index에는 실제 단어에 매핑한 정수에 -3을 해주었으므로 +3을 해준다.\n",
    "index_to_word = {index + 3: word for word, index in word_index.items()}\n",
    "\n",
    "# <pad>:0, <sos>:1, <unk>:2 토큰 넣어주기\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "norman-deficit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T15:10:07.531761Z",
     "start_time": "2021-04-11T15:10:07.399682Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 뉴스 데이터를 텍스트 데이터로 변환(훈련, 테스트)\n",
    "\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "critical-change",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T15:10:07.587061Z",
     "start_time": "2021-04-11T15:10:07.533318Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-angola",
   "metadata": {},
   "source": [
    "### 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bearing-serbia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T15:10:08.289268Z",
     "start_time": "2021-04-11T15:10:07.592077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 14227)\n"
     ]
    }
   ],
   "source": [
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "varying-darwin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T15:10:08.333221Z",
     "start_time": "2021-04-11T15:10:08.290599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 14227)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "excessive-investigator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T15:10:08.511776Z",
     "start_time": "2021-04-11T15:10:08.334462Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test_dtm = dtmvector.transform(x_test)  # DTM 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm)  # DTM -> TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "prerequisite-albert",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-11T15:31:13.157115Z",
     "start_time": "2021-04-11T15:10:08.512866Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나이브 베이즈 정확도: 0.6331255565449688\n",
      "나이브 베이즈 f1 score: 0.5498212868794679\n",
      "CMB 정확도: 0.7720391807658059\n",
      "CMB f1 score: 0.7448186439256785\n",
      "로지스틱 회귀 정확도: 0.8125556544968834\n",
      "로지스틱 회귀 f1 score: 0.8055609374268625\n",
      "SVM 정확도: 0.780053428317008\n",
      "SVM f1 score: 0.7747889325121782\n",
      "Decision Tree 정확도: 0.6193232413178985\n",
      "Decision Tree f1 score: 0.5755585664009136\n",
      "랜덤 포레스트 정확도: 0.6714158504007124\n",
      "랜덤 포레스트 f1 score: 0.6406930098492383\n",
      "그래디언트 부스팅 트리 정확도: 0.7707034728406055\n",
      "그래디언트 부스팅 트리 f1 score: 0.7679462922982356\n",
      "보팅 정확도: 0.8165627782724845\n",
      "보팅 f1 score: 0.8132601841863839\n"
     ]
    }
   ],
   "source": [
    "models_accuracy(tfidfv, tfidfv_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-first",
   "metadata": {},
   "source": [
    "## 머신러닝 결과 비교(정확도와 f1 score)\n",
    "- 3천개    \n",
    "  - 정확도: Decision Tree(63%) < 랜덤 포레스트 정확도(68.6%) < 나이브 베이즈(68.7%) < SVM(75%) < CMB(76%) < 그래디언트 부스팅 트리(77.6%) < 로지스틱 회귀(79%) < 보팅(81.0%)       \n",
    "  - f1 score: Decision Tree(58%) < 나이브 베이즈(63%) < 랜덤 포레스트 정확도(65.9%) < CMB(74%) < SVM(75%) < 그래디언트 부스팅 트리(77.2%) < 로지스틱 회귀(79%) < 보팅(80.6%) \n",
    "\n",
    "- 5천개     \n",
    "  - 정확도: Decision Tree(62%) < 나이브 베이즈(67%) < 랜덤 포레스트 정확도(70%) < 그래디언트 부스팅 트리(76.8%) < CMB(77.1%) < SVM(77.2%) < 로지스틱 회귀(81%) < 보팅(81.6%)       \n",
    "  - f1 score: Decision Tree(57%) < 나이브 베이즈(60%) < 랜덤 포레스트 정확도(68%) < CMB(75%) < 그래디언트 부스팅 트리(76.62%) < SVM(76.69%) < 로지스틱 회귀(80%) < 보팅(81.2%) \n",
    "\n",
    "- 8천개       \n",
    "  - 정확도: Decision Tree(62%) < 나이브 베이즈(66%) < 랜덤 포레스트 정확도(66.7%) < 그래디언트 부스팅 트리(76%) < SVM(76.7%) < CMB(77.1%) < 로지스틱 회귀(81%) < 보팅(81.3%)         \n",
    "  - f1 score: Decision Tree(57%) < 나이브 베이즈(58%) < 랜덤 포레스트 정확도(64%) < CMB(75%) < 그래디언트 부스팅 트리(76%) < SVM(76.2%) < 로지스틱 회귀(80%) < 보팅(80.9%) \n",
    "\n",
    "- 1만개             \n",
    "  - 정확도: Decision Tree(62%) < 나이브 베이즈(66%) < 랜덤 포레스트 정확도(67%) < 그래디언트 부스팅 트리(76.7%) < CMB(77%) < SVM(77.4%) < 로지스틱 회귀(80.8%) < 보팅(81.2%)      \n",
    "  - f1 score: 나이브 베이즈(57.6%) < Decision Tree(57.8%) < 랜덤 포레스트 정확도(64%) < CMB(75%) < 그래디언트 부스팅 트리(76%) < SVM(77%) < 로지스틱 회귀(80%) < 보팅(80.8%) \n",
    "\n",
    "- 1만 5천개   \n",
    "  - 정확도: Decision Tree(62%) < 나이브 베이즈(63%) < 랜덤 포레스트 정확도(67%)  < 그래디언트 부스팅 트리(77.1%) < CMB(77.2%) < SVM(78%) < 로지스틱 회귀(81%) < 보팅(81.7%)       \n",
    "  - f1 score: 나이브 베이즈(55%) < Decision Tree(57%) < 랜덤 포레스트 정확도(64%) < CMB(74%) < 그래디언트 부스팅 트리(77%) < SVM(78%) < 로지스틱 회귀(80.1%) < 보팅(81.3%) \n",
    "\n",
    "- 전체    \n",
    "  - 정확도: 나이브 베이즈(60%) < Decision Tree(62%) < 랜덤 포레스트 정확도(65%) < CMB(76%) < 그래디언트 부스팅 트리(77%) < SVM(78%) < 로지스틱 회귀(81%) < 보팅(81.9%)        \n",
    "  - f1 score: 나이브 베이즈(50%) < Decision Tree(58%) < 랜덤 포레스트 정확도(62%) < CMB(73%) < 그래디언트 부스팅 트리(76%) < SVM(77%) < 로지스틱 회귀(80.7%) < 보팅(81.4%) \n",
    "  \n",
    "  \n",
    "\n",
    "- 정확도    \n",
    "위의 결과를 보았을 때 전체적으로 보팅이 가장 높은 성능을 보였고, 단어의 수는 전체일 때 가장 높은 정확도를 보였다. 단어의 수가 줄어들수록 정확도는 조금씩 떨어지는 것을 볼 수 있었다. 모델마다 단어의 수에 따라 정확도 순위는 조금씩 바뀌었다. 예를 들어 나이브 베이즈의 경우는 단어의 수가 적을수록 더 높은 결과를 보였다. 그러나 전체적으로 보았을 때는 단어 수를 조절해도 머신러닝 모델의 정확도는 아주 큰 차이를 보이는 것 같지는 않다. \n",
    "\n",
    "각 모델의 정확도의 순위도 단어의 수에 따라 변했다. 그래서 보팅 외에는 어떤 모델이 성능이 더 좋은지를 단정하기는 어려웠다.  \n",
    "\n",
    "- f1 score    \n",
    "f1 score는 데이터가 불균형한 다중 분류 모델에서 사용되는 평가 지표이지만 위의 결과를 보면 정확도와 순위와 점수가 거의 비슷하다는 것을 볼 수 있다. \n",
    "\n",
    "\n",
    "- 참고    \n",
    "num_words(단어의 수)에 따라 TF-IDF 행렬의 크기가 달라짐을 볼 수 있었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-convert",
   "metadata": {},
   "source": [
    "### 4. 딥러닝 모델과 비교해 보기\n",
    "위 과정을 통해 나온 최적의 모델과 단어 수 조건에서, 본인이 선택한 다른 모델을 적용한 결과와 비교해 봅시다. 감정분석 등에 사용했던 RNN이나 1-D CNN 등의 딥러닝 모델 중 하나를 선택해서 오늘 사용했던 데이터셋을 학습해 보고 나오는 결과를 비교해 봅시다. 단, 공정한 비교를 위해 이때 Word2Vec 등의 pretrained model은 사용하지 않도록 합니다.\n",
    "\n",
    "```num_words=10000```으로 하였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "durable-rouge",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:44:23.671502Z",
     "start_time": "2021-04-22T12:44:23.669173Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "demanding-struggle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:44:24.746920Z",
     "start_time": "2021-04-22T12:44:24.284681Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cutting-private",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:44:24.750338Z",
     "start_time": "2021-04-22T12:44:24.748060Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982 2246\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "otherwise-review",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:44:24.913739Z",
     "start_time": "2021-04-22T12:44:24.910145Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스의 수: 46\n"
     ]
    }
   ],
   "source": [
    "# 클래스의 수 보기\n",
    "num_classes = max(y_train) + 1\n",
    "print(\"클래스의 수: {}\".format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dominican-shannon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:44:25.582469Z",
     "start_time": "2021-04-22T12:44:25.354827Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 뉴스의 최대 길이: 2376\n",
      "훈련용 뉴스의 평균 길이: 145.5398574927633\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYpklEQVR4nO3df7RdZX3n8fcHHUwoLSVyIZofxgJai0iFSC3VRimCwoC/RtshUEFXQZdoKwtLyoxTO2VRFVRcOmhjRcoIRnHUqChtReIUaMVg/VEsNXUWSBoIl6C0SFAq3/lj7yuH605yT3LPPTfnvl9rnZWzn/3sfb77rJv7vc+P/exUFZIkTbbHsAOQJM1OJghJUicThCSpkwlCktTJBCFJ6vTYYQcwXfbbb79atmzZsMOQpN3KzTfffE9VjXXtG5kEsWzZMtavXz/sMCRpt5Lk9m3tG2iCSPIy4CDgCOAPaLq0TgO2ABuq6tq23jnARmBxVV3Ulh0DHAiMAZdW1aZBxipJerSBJYgkPw98r6o+meQk4CXAM4E3VtWDSS5Lch3wQmBjVa1JsjLJccAXgZVVdXqS+cDFwJmDilWS9LMGNkhdVf9eVRN9PocC/xdYUFUPtmUbgMOBk4Dr2rJ1wInAs4Bb2/NsBcaSZFCxSpJ+1kBnMSXZM8m7gIOBe4D7e3bfCTwJWASMt2V3AUva1+aeuvcDCzrOf0aS9UnWj4+PT94tSdoFA00QVfXjqjob+BJNF1Hvwk8FpH31lneVTdSdfP7VVbW8qpaPjXUOwkuSdtKM3AdRVZfTtCL26SleCNwObKIZiAbYH7iDZsD6gJ66e9MMbEuSZsiMJIgkjwe+DdzXDjpDM7vpZuBq4Oi2bAWwFriJZtyCJPOAzeWys5I0owY5i2kpcCXwUeAB4N00LYRzk9wNXFlVDwNrk5yX5BRgYVWtaY+/IslZwL7A+YOKU5LULaPyh/ny5cvLG+UkqT9Jbq6q5V37RuZO6kFZturqzvLb3nbCDEciSTPLxfokSZ1MEJKkTiYISVInE4QkqZMJQpLUyQQhSepkgpAkdTJBSJI6mSAkSZ1MEJKkTiYISVInE4QkqZMJQpLUyQQhSepkgpAkdTJBSJI6mSAkSZ1MEJKkTiYISVInE4QkqZMJQpLUyQQhSepkgpAkdTJBSJI6mSAkSZ0eO8iTJzkT2A9YCpxXVVuSrAYeAB4G3lxVP0lyDrARWFxVF7XHHgMcCIwBl1bVpkHGKkl6tIEliCTPBq6vqluSHAy8Psk1wJVVta6n3vHAxqpak2RlkuOALwIrq+r0JPOBi4EzBxWrJOlnDbKL6TtVdUv7fhxYAKwAzkyyqv3FD3AScF37fh1wIvAs4FaAqtoKjCXJAGOVJE0ysARRVff2bL4S+GxVXQicDNwHfLDdt4gmgQDcBSxpX5t7jr+fJsE8SpIzkqxPsn58fHzybknSLhj4IHWSMeCoqroWoBrvB5Yk2RMIUL2HdJRVW/YoVbW6qpZX1fKxsbGBXYMkzUUDTRBtt9A7gFUdu++g+cW/iWYgGmD/tnwjcEBP3b2BLYOLVJI02aBbEGcDH6mqu5L8tIsoyR40A9MPAVcDR7e7VgBrgZuAQ9u684DNVVVIkmbMIGcxHQ2cBqxN8nzgcUmOAG4AbgcuBKiqtUnOS3IKsLCq1rTHX5HkLGBf4PxBxSlJ6jawBFFVX6JtBUyh7gUdZddMe1CSpCnzTmpJUicThCSpkwlCktTJBCFJ6mSCkCR1MkFIkjqZICRJnUwQkqROJghJUqeBPlFud7Fs1dXDDkGSZh1bEJKkTiYISVInE4QkqZMJQpLUyQQhSepkgpAkdTJBSJI6mSAkSZ1MEJKkTiYISVInE4QkqZMJQpLUyQQhSeo05QSR5LeSHJBkaZJ3JnnuIAOTJA1XPy2IJ1fVZuAD7WvhYEKSJM0G/SSIJHkjcE1VbQCeNKCYJEmzQD8PDPoIcFBVfSvJQYBP2ZGkEdZPgjgRWAR8C9gCHLyjA5KcCewHLAXOA+YBp7XHb6iqa9t65wAbgcVVdVFbdgxwIDAGXFpVm/qIVZK0i/pJEI8DvgtQVd9PcjJw07YqJ3k2cH1V3ZLkYOD1wGLgjVX1YJLLklwHvBDYWFVrkqxMchzwRWBlVZ2eZD5wMXDmzlygJGnn9DMGcf/EmyS/wI7HIL5TVbe078dpWhILqurBtmwDcDhwEnBdW7aOpqXyLOBWgKraCowlSR+xSpJ2UT8J4lvAkUk+ALyXpstom6rq3p7NVwI30JNkgDtpkswimgQCcBewpH1t7ql7P7Bg8mckOSPJ+iTrx8fHJ++WJO2CKSeIqvqXqvrvVfXaqnoVj/5lv01JxoCjaFoJ1XtKIO2rt7yrbKLu5JhWV9Xyqlo+NjY21UuRJE3BdscgklwJPNi1i6Yb6Ok7OD7AO4BVNAPT+/TsXgj8I7CJZiD6bmB/4A6aAevn9NTduz1ekjRDdjRIfW5V3dG1I8khUzj/2cBHququJAuA+5LMb8cVDgLeDjwROBpYA6wA1tIMfr+u/Zx5wOaqqq4PkCQNxnYTRG9yaAemXws8Abi2qj63vWOTHE0zpXVtkucDewJ/DJyb5G7gyqp6uN1/XpJTgIVVtaY9/ookZwH7Aufv7AVKknZOP9Nc3wtcAnwdOCTJK6rqqm1VrqovAYd27HprR90LOsqu6SM2SdI062cW061V9ZWq+lFVfQ34EUASV4SVpBHUzy/3f0/yS+1qrkuB32j/PWNAsUmShqifLqYjaG52mxgsfgA4HXgmzequkqQR0k+C+L2q+o+JjSTz2iUz9htAXJKkIesnQfxKkuNpZiMFeAbw8qq6ZyCRSZKGqp8EcQHwh8AP2+3nbKeuJGk310+C+HRVfXtiI4ktB0kaYf0kiB8l+TNgK00X02HAywYSlSRp6PpJEK8AzqWZvQR2MUnSSOsnQXyiqv5pYqNdLkOSNKL6SRBHJnk6zTLfP53FNJCoJElD10+C+Gvgmzxyo9xvTn84kqTZYsoJoqo+07ud5MvTH44kabaYcoJol+M+emKT5hGgLx5EUJKk4euni+nXaZ4HsQK4FjhhIBFJkmaFflZzvb6qfgw8TPPo0MMGE5IkaTboJ0F8KcnLqupa4A19HitJ2s30M0i9Gfhku/kZ4NvbqS5J2s1NuRWQ5B1J9k/yNpr7H143uLAkScPWTzfRV4H5wNKqeguwaTAhSZJmg34SxB3A7wJvSHIwzUC1JGlE9TMG8ffA37ebW4ANA4lIkjQrOBNJktRpuwkiyQEzFYgkaXbZUQviTybeJPnPvTuSPH4gEUmSZoUdjUFckuR3adZeekGSBW15aFZzfc0gg5MkDc92E0RVfTPJd4BfA24Fbu/ZfcSOTp5kD+BU4PNVNd6WraZ5Kt3DwJur6idJzgE2Aour6qK23jHAgcAYcGlVOa1WkmbQDmcxVdWDwJfbF0nmV9XWJDdM4fxH0dxU92VgPMmRwJVVtW6iQpLjgY1VtSbJyiTHAV8EVlbV6UnmAxcDZ/Z3aZKkXdHPndTLk3wG+FCSvwR+ZUfHVNX1wNd6ilYAZyZZ1f7iBzgJuK59vw44EXgWTYuFqtoKjCXJVGOVJO26fqa5Lq+qk6rq5Kp6Fc0jR/tSVRcCJwP3AR9sixcB4+37u4Al7Wtzz6H30zx/4lGSnJFkfZL14+Pjk3dLknZBPwni/03avm9nPrAa7weWJNmTZsC7eqqko6zassnnWl1Vy6tq+djY2M6EI0nahn4SxFOTrEiyJMlLmEIX0w7cQfOLfxPNQDTA/m35RqD3Hoy9ae7eliTNkH4SxCXAk4E/BPYDLtzZD21nN22sqoeAq3nkUaYrgLXATcChbd15wOaqqq5zSZIGo5+1mH4CXNa+piTJITS//B9K8j7gU8ANNNNlL2zPuzbJee0zrxdW1Zr22CuSnAXsC5w/1c+UJE2Pfp5J3bequoXmhroJR2+j3gUdZdcMKi5J0o65WJ8kqVM/90GsGmQgkqTZpZ8WxKPuQ0hy6DTHIkmaRfoZg1iQ5G9opqEGeBrw7IFEJUkaun4SxGXt0hkAJOkccJYkjYZ+uph+kOSlAEl+EfingUQkSZoV+kkQxwJ7AVTVD4CzBhGQJGl26KeL6V8mbT9lOgORJM0u/SSIe4GVSZbTrMP00cGEJEmaDfpZauN64Pok+wH3VtXDgwtLkjRsU04QSY4Ffh/4HnBbksur6s6BRSZJGqp+uphOBU6caDkkeSXw8YFEJUkaun5mMd04qVtp63QHI0maPbbZgkhyBHBCT9FBSZ5M8/jPx9AsvfHZwYYnSRqW7XUxfZ1mqe5PduybB/zcIAKSJM0O20wQ7QOC3r2t/UkOHkhEkqRZoZ9ZTG8FDgQeolms71eBZw4kKknS0PUzi2mfqjp1YiPJ4gHEI0maJfqZxfTlJOnZ/vnpDkaSNHv004I4BnhVku/TdDE9k6abSZI0gvpJEA9U1UsnNuxikqTR1k8X098meUzP9l7THYwkafbopwVxBnBykq04i0mSRl4/CeI1VXX3xEaSpQOIZ7exbNXVneW3ve2EznJJ2t1MKUEk2QN4WpJf7ik+HLh4EEFJkoZvSgmiqh5OcjJwY1u0D/ALA4tKkjR0/XQxvb6q/mNiI8mrBxCPJGmW6KeL6TeSVFs0H3gZcOkUjjsV+HxVjSdZBJwGbAE2VNW1bb1zgI3A4qq6qC07hmZpjzHg0qra1Oe1SZJ2wZSmubbPgfgvwJPb1/7A2VM49Cjg5Tyy8usfA++sqg8ApybZI8nxwMaqWgPcmeS4djrtyqr6c+Cd7XGSpBnUzzOp39C7nWRsCsdc37YEJloTC6rqwXb3BpqB7pN4JAGsA/4IuA+4tT3H1iRjSVJVhSRpRvSzmuuJwItongUR4BnAEX181uNpHjY04U7gScAiYLwtuwtY0r4299S9n+YBRVsmxXQGzf0ZLF06p2fdStK062eQ+hXA6e1zIkhydJ+fFaC3BVBt2eTyrrKJuo9SVauB1QDLly+3dSFJ06ifpTa+MJEcWt/s87O20EyPnbAQuB3YRDMQDc3Yxh00A9YH9NTdm0mtB0nSYPWTIF6Y5GNJLk3yYeAL/XxQm1zuSzK/LToIuBm4GphojawA1gI3AYcCJJkHbHb8QZJmVj9dTJdU1VcmNpL81o4OSHIIzS//h5K8l2Yw+twkdwNXtrOj1iY5L8kpwMJ2NhNJrkhyFrAvcH4fcUqSpkE/s5i+Mmn72ikccwvwmz1F/wa8taPeBR1l10w1NknS9Ouni0mSNIeYICRJnUwQkqROJghJUicThCSpkwlCktSpn/sgNAU+ilTSqLAFIUnqZIKQJHUyQUiSOpkgJEmdTBCSpE4mCElSJxOEJKmTCUKS1MkEIUnqZIKQJHUyQUiSOpkgJEmdTBCSpE4mCElSJxOEJKmTCUKS1MkEIUnqZIKQJHUyQUiSOg3lmdRJDgPeBPwA+CqwDjgN2AJsqKpr23rnABuBxVV10TBilaS5aigJAngBcHpVFUCS1cAbq+rBJJcluQ54IbCxqtYkWZnkuKr6qyHFK0lzzox3MSUJsAK4PMmxSfYAFlTVg22VDcDhwEnAdW3ZOuDEmY5VkuayGW9BtK2GE5M8HvjfwD7A/T1V7gSeBCwCxtuyu4Alk8+V5AzgDIClS5cOMGpJmnuG1cVEVW1J8ibg3cDm3l1A2lf1lKfjHKuB1QDLly+vyftnk2Wrru4sv+1tJ8xwJJI0NcOexXQHTXLYp6dsIXA7sAkYa8v2b+tKkmbIsBPEkcBVwH1J5rdlBwE3A1cDR7dlK4C1Mx+eJM1dM97FlOT5wFuAjwH3VtVVSf4RODfJ3cCVVfUwsDbJeUlOARZW1ZqZjlWS5rJhDFJfxyOzkybKvge8taPuBTMUliRpkmF3MUmSZikThCSpkwlCktTJBCFJ6mSCkCR1MkFIkjoNbakNNVyCQ9JsZQtCktTJBCFJ6mSCkCR1MkFIkjqZICRJnZzFNEs5u0nSsNmCkCR1MkFIkjqZICRJnUwQkqROJghJUidnMe1mnN0kaabYgpAkdTJBSJI62cU04uySkrSzTBAjYluJQJJ2ll1MkqROtiDmKLueJO2ICUJTsr0uLJOKNJpMEHqU6RzLsJUi7d5mdYJI8tvAPGAZ8M6qun+4EamLA+TSaJq1CSLJAuCoqvr9JIuA89qXdnP9JhRbHNJwzNoEARwL3AhQVf+a5GlDjkdDYkKRhmM2J4glwFd7tvecXCHJGcAZ7eb9Sf55Jz5nP+CenThuVIzc9eftfR8yct9Bn7z+uX39T9rWjtmcIALU9ipU1Wpg9S59SLK+qpbvyjl2Z3P9+sHvwOuf29e/PbP5RrmNwAE92z8eViCSNBfN5gTxN8BzAZI8Afj2cMORpLll1nYxVdV4kq8keQ2wGPizAX3ULnVRjYC5fv3gd+D1q1OqttvNL0mao2ZzF5MkaYhMEJKkTrN2DGImzKWlPJIcBrwJ+AHN/SXrgNOALcCGqrq2rXcOzQyyxVV10TBinS5J9gBOBT7fjmktYorXnOQY4EBgDLi0qjYN4RJ22eTvoC1bDTwAPAy8uap+MqrfQZIzae5zWEqzEsM85tjPwC6pqjn5AhYA72nfLwIuGHZMA77ec2jHnNrt1cC89v1lNK3J44HfactWAscNO+5dvObnAJ8BlvVzzcBjgA+3ZfOBPx/2tUzjd3Ak8LxJdUbyOwCeDRzSvj8Y+B9z8WdgV15zuYvpUUt5ACO7lEeSACuAy5Mc2/5VuaCqHmyrbAAOB04CrmvL1gEnznSs06mqrge+Bj/9S3qq1/ws4Nb2HFuBsfY73O30fgetFcCZSVYlmd+Wjep38J2quqV9P07TkphzPwO7Yi4niCXA5p7tn1nKY1RU40TgD9rXy4He7rQ7aW63X0TzHwngLprvaFQ8nqlf8+SfjftpWpy7vaq6EDgZuA/4YFs8kt9BVd3bs/lK4Ab8GejLXE4QO1zKY9RU1RaacYjTefS1F833Mfk7GaW/mCZf2/aueVt1R0L7B8P7gSVJ9mTEv4MkY8BRNK0Efwb6MJcTxFxdyuMOmr+M9ukpWwjcDmyiGZAD2L+tOyq2MPVrnvyzsXd7/Ki5g+YX38h+B2230DuAVfgz0Le5nCDm6lIeRwJXAff19EEfBNwMXA0c3ZatANbOfHiDUVU/YerXfBNwKECSecDmakcrR0U7JrOxqh5itL+Ds4GPVNVdNMnBn4E+zOk7qZOcAjyOZimPkZ3mmuT5wFuAjwH3VtVVSZYCrwbuBv65Hpnudx7wPWBh7f7TXA8B3g/8FfBe4BeZ4jUneSHNL5B9gQ/VbjrFcdJ38D7gUzR98bcDn2q7HUfyO0hyNPAeHvlDZ0+a72BO/QzsijmdICRJ2zaXu5gkSdthgpAkdTJBSJI6mSAkSZ1MEJKkTiYIjZQkv5rkf03zOQ/blXMmOSHJB6Yzph183vFJ/ttMfZ5GlwlCI6Wqvg783DSf8xs7e84kvwbcWVWvnc6YduDbwH+awc/TiDJBSB3aVsOKaTjVi4B7d1hLmoXm9AODNNqSHE5zl/wTaZZ2vh14O7CGZkmFW6vqfUl+D/g3mhU8Xwy8Fng98OMki6vqCmCvJK+neVbAu6pq3aTPeiLwUuC7NEs0/CXwIPAM4NVJPl1VX+up/2Kah9csraoL2wc6HQa8BHhLVd2S5AKa9X9+BLwMeFt7vhe09fYBPgx8lGa5+sdV1dmT4nouzSqkBwF/TbP20tPb17sn7qSWupggNMpOBb5Ms6zCQVV1bZKqqquAq5JMLHf9UppnADwMHNj+cr4RuK0nEewLXAJ8HPhTmucG9HoLcE5V/TDJN4Dzq+qMJN8ELquq2ybVPxZ4M48sHvfUqro8yWZgOXALTVIbr6rPJXkYeExVXZRkK/DMqroxyb1VdTlAkj9qu7Q2t9uheQDONe138BSaZHkD8Dnm4Oqk6o8JQqNsr6r69KSy3vW2JvrpzwfeAHwH+J/bONe/tou1jbeLt022pKp+CFBVd7Ytiu35C+CzwIeAK4HPJzmBpiVwT1uneuJ9ANjavv8hjzy/5KGec/4DTQKYeI7BGE2C+fREhSR7Ae9qj3/dDmLUHOcYhEbZfkkeC5Bkew97+a9VdXFVfb6q7mzLiv7+f9ybZP+ez/ruDur/kKa76rfb7T+l+Uv/H/r4zMmeDPxdz/YW4JCJjTauxe2A+Y00j9qUtskWhEZKkucBT28fEvMe4BNJvgv8RftX/XOSLKOZlfTcJL8E/F2Sj9MMJt9J89zibwBvTvIQTVfMU9tzPhV4SpIDqqr3iWOrgNck+RawFPiTJAuB5wHfT3JJu7T2hN9pP+ML7fYTaMY9tgDPT/J/gF8HFiX5W5rnKy/tef9Emm6usSRvoHmGwa1VdVeS02gemTkf+GiST9B0V70POKzthppH09UkbZOruWrOS7KKZlD5HprnAhxUVdN6L8WgJLmsqk4bdhwaTXYxSU0L4UU0XT570cwMmvWS/DJweJLnDDsWjSZbENJuLu3UrGHHodFjgpAkdbKLSZLUyQQhSepkgpAkdTJBSJI6/X+KK1+j5GA1AgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"훈련용 뉴스의 최대 길이: {}\".format(max(len(l) for l in x_train)))\n",
    "print(\"훈련용 뉴스의 평균 길이: {}\".format(sum(map(len, x_train))/len(x_train)))\n",
    "      \n",
    "plt.hist([len(s) for s in x_train], bins=50)\n",
    "plt.xlabel(\"length of samples\")\n",
    "plt.ylabel(\"number of samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "greenhouse-separate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:44:25.811980Z",
     "start_time": "2021-04-22T12:44:25.583844Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트용 뉴스의 최대 길이: 1032\n",
      "테스트용 뉴스의 평균 길이: 147.66117542297417\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"테스트용 뉴스의 최대 길이: {}\".format(max(len(l) for l in x_test)))\n",
    "print(\"테스트용 뉴스의 평균 길이: {}\".format(sum(map(len, x_test))/len(x_test)))\n",
    "      \n",
    "plt.hist([len(s) for s in x_test], bins=50)\n",
    "plt.xlabel(\"length of samples\")\n",
    "plt.ylabel(\"number of samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-fountain",
   "metadata": {},
   "source": [
    "훈련용 뉴스 기사 데이터와 테스트용 뉴스 기사 데이터에 있는 각각의 뉴스의 길이는 다르다.따라서 모델의 입력으로 사용하고자 모든 뉴스 기사의 길이를 동일하게 맞춰준다. keras.preprocessing.sequence.pad_sequences()를 사용하면 단어의 수가 100개보다 많으면 100개만 선택하고 나머지는 제거하며, 100개보다 부족한 경우에는 부족한 부분을 0으로 패딩한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "apparent-diving",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:44:26.359412Z",
     "start_time": "2021-04-22T12:44:26.240723Z"
    }
   },
   "outputs": [],
   "source": [
    "# padding\n",
    "maxlen = 100\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, padding='pre', maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, padding='pre', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "romantic-education",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:44:26.554048Z",
     "start_time": "2021-04-22T12:44:26.550022Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    1   53  134   26   14  102   26   39\n",
      " 5150   18   14 2013   18   86   44 4121   18   14   44 4577   18  180\n",
      "  183   32 4335   18   14   32 6118   18   29   53 1045   26   14   19\n",
      "  821   15   39   32 1842   18   14   32 5821   18   86  284   32   11\n",
      "   14  284   12   11  180  183   32 3762   18   14   32 4846   18  123\n",
      "   48   98   39  235  785   18  150  728   22    2    5  205  131  291\n",
      "   17   12]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abroad-empire",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:44:30.162110Z",
     "start_time": "2021-04-22T12:44:30.159403Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  4  3 ... 25  3 25]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "opponent-circuit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:44:31.073526Z",
     "start_time": "2021-04-22T12:44:31.070884Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터의 레이블에 원-핫 인코딩을 한다. \n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "completed-credits",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:44:31.674870Z",
     "start_time": "2021-04-22T12:44:31.671629Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "separate-notification",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:44:32.538424Z",
     "start_time": "2021-04-22T12:44:32.536008Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 46) (2246, 46)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "indoor-portugal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:44:33.556872Z",
     "start_time": "2021-04-22T12:44:33.551282Z"
    }
   },
   "outputs": [],
   "source": [
    "# http://blog.naver.com/PostView.nhn?blogId=wideeyed&logNo=221226716255 참고\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "    # Precision = (True Positive) / (True Positive + False Positive)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-operations",
   "metadata": {},
   "source": [
    "1. RNN(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fossil-nightmare",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T17:36:14.552536Z",
     "start_time": "2021-04-19T17:36:14.356168Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 1,128,494\n",
      "Trainable params: 1,128,494\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기(10,000개의 단어)\n",
    "word_vector_dim = 100  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# RNNmodel 설계 \n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(128))   # LSTM 레이어를 사용하였다. LSTM state 벡터의 차원수는 8\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(46, activation='softmax'))  # 최종 출력은 긍정/부정을 나타내는 1 dim\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "after-helicopter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T17:36:14.673613Z",
     "start_time": "2021-04-19T17:36:14.664862Z"
    }
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', precision, recall, f1score])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "anonymous-bryan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T17:36:33.187270Z",
     "start_time": "2021-04-19T17:36:15.297088Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "57/57 [==============================] - 2s 22ms/step - loss: 3.2489 - accuracy: 0.3082 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: 0.0000e+00 - val_loss: 2.3959 - val_accuracy: 0.3450 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
      "Epoch 2/30\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 2.2792 - accuracy: 0.4105 - precision: 0.4319 - recall: 0.1291 - f1score: 0.1978 - val_loss: 2.0950 - val_accuracy: 0.4719 - val_precision: 0.9733 - val_recall: 0.2488 - val_f1score: 0.3943\n",
      "Epoch 3/30\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 2.0468 - accuracy: 0.4966 - precision: 0.9426 - recall: 0.2821 - f1score: 0.4329 - val_loss: 2.0093 - val_accuracy: 0.5031 - val_precision: 0.9449 - val_recall: 0.2800 - val_f1score: 0.4299\n",
      "Epoch 4/30\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 1.9744 - accuracy: 0.5214 - precision: 0.9367 - recall: 0.3048 - f1score: 0.4578 - val_loss: 1.9242 - val_accuracy: 0.5047 - val_precision: 0.9626 - val_recall: 0.2764 - val_f1score: 0.4272\n",
      "Epoch 5/30\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 1.8293 - accuracy: 0.5302 - precision: 0.8951 - recall: 0.3756 - f1score: 0.5213 - val_loss: 1.9266 - val_accuracy: 0.4986 - val_precision: 0.8791 - val_recall: 0.3586 - val_f1score: 0.5062\n",
      "Epoch 6/30\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 1.8361 - accuracy: 0.5171 - precision: 0.8552 - recall: 0.4384 - f1score: 0.5755 - val_loss: 1.8415 - val_accuracy: 0.5186 - val_precision: 0.8160 - val_recall: 0.4227 - val_f1score: 0.5561\n",
      "Epoch 7/30\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 1.7310 - accuracy: 0.5609 - precision: 0.9049 - recall: 0.4660 - f1score: 0.6127 - val_loss: 1.8941 - val_accuracy: 0.5081 - val_precision: 0.7395 - val_recall: 0.4264 - val_f1score: 0.5393\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 1.7561 - accuracy: 0.5458 - precision: 0.8456 - recall: 0.4564 - f1score: 0.5912 - val_loss: 1.7522 - val_accuracy: 0.5353 - val_precision: 0.8483 - val_recall: 0.4514 - val_f1score: 0.5829\n",
      "Epoch 9/30\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 1.6440 - accuracy: 0.5729 - precision: 0.9077 - recall: 0.4909 - f1score: 0.6357 - val_loss: 1.6773 - val_accuracy: 0.5721 - val_precision: 0.9007 - val_recall: 0.4717 - val_f1score: 0.6129\n",
      "Epoch 10/30\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 1.5496 - accuracy: 0.5943 - precision: 0.9290 - recall: 0.5061 - f1score: 0.6542 - val_loss: 1.6949 - val_accuracy: 0.5782 - val_precision: 0.8878 - val_recall: 0.4784 - val_f1score: 0.6152\n",
      "Epoch 11/30\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 1.4602 - accuracy: 0.6178 - precision: 0.9503 - recall: 0.5199 - f1score: 0.6712 - val_loss: 1.6466 - val_accuracy: 0.5854 - val_precision: 0.8916 - val_recall: 0.4711 - val_f1score: 0.6103\n",
      "Epoch 12/30\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 1.3725 - accuracy: 0.6430 - precision: 0.9431 - recall: 0.5367 - f1score: 0.6824 - val_loss: 1.5787 - val_accuracy: 0.6121 - val_precision: 0.8647 - val_recall: 0.4920 - val_f1score: 0.6197\n",
      "Epoch 13/30\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 1.2196 - accuracy: 0.6903 - precision: 0.9372 - recall: 0.5803 - f1score: 0.7157 - val_loss: 1.5626 - val_accuracy: 0.6299 - val_precision: 0.8126 - val_recall: 0.5376 - val_f1score: 0.6439\n",
      "Epoch 14/30\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 1.0895 - accuracy: 0.7287 - precision: 0.9327 - recall: 0.6254 - f1score: 0.7476 - val_loss: 1.5254 - val_accuracy: 0.6338 - val_precision: 0.8226 - val_recall: 0.5345 - val_f1score: 0.6448\n",
      "Epoch 15/30\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.9728 - accuracy: 0.7553 - precision: 0.9390 - recall: 0.6587 - f1score: 0.7736 - val_loss: 1.6337 - val_accuracy: 0.6283 - val_precision: 0.7935 - val_recall: 0.5608 - val_f1score: 0.6562\n",
      "Epoch 16/30\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.9545 - accuracy: 0.7511 - precision: 0.9260 - recall: 0.6662 - f1score: 0.7738 - val_loss: 1.6180 - val_accuracy: 0.6388 - val_precision: 0.8015 - val_recall: 0.5624 - val_f1score: 0.6599\n",
      "Epoch 17/30\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.8119 - accuracy: 0.7912 - precision: 0.9314 - recall: 0.7204 - f1score: 0.8118 - val_loss: 1.6349 - val_accuracy: 0.6383 - val_precision: 0.7683 - val_recall: 0.5647 - val_f1score: 0.6501\n",
      "Epoch 18/30\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.7483 - accuracy: 0.8005 - precision: 0.9378 - recall: 0.7368 - f1score: 0.8245 - val_loss: 1.6750 - val_accuracy: 0.6511 - val_precision: 0.7811 - val_recall: 0.6072 - val_f1score: 0.6821\n",
      "Epoch 00018: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=128, epochs=30, callbacks=[es], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "invisible-character",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T17:36:33.481276Z",
     "start_time": "2021-04-19T17:36:33.189099Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 4ms/step - loss: 1.7732 - accuracy: 0.6358 - precision: 0.7532 - recall: 0.5915 - f1score: 0.6612\n"
     ]
    }
   ],
   "source": [
    "_loss, _precision, _accuracy, _recall, _f1score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "solid-mississippi",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-19T17:36:54.885388Z",
     "start_time": "2021-04-19T17:36:54.882167Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.773, accuracy: 0.753, precision: 0.636, recall: 0.592, f1 score: 0.661\n"
     ]
    }
   ],
   "source": [
    "print('loss: {:.3f}, accuracy: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1 score: {:.3f}'.format(_loss, _accuracy, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-pressure",
   "metadata": {},
   "source": [
    "2. 1-D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "blocked-mapping",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:44:46.728901Z",
     "start_time": "2021-04-22T12:44:46.658314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 16)          11216     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 46)                414       \n",
      "=================================================================\n",
      "Total params: 1,013,574\n",
      "Trainable params: 1,013,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 100  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성(1D-CNN)\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(Dropout(0.3))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(keras.layers.Dense(46, activation='softmax')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "curious-canal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:44:47.382352Z",
     "start_time": "2021-04-22T12:44:47.373210Z"
    }
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', precision, recall, f1score])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "another-stake",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:45:03.155769Z",
     "start_time": "2021-04-22T12:44:48.784513Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "57/57 [==============================] - 2s 20ms/step - loss: 3.7644 - accuracy: 0.0439 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1score: 0.0000e+00 - val_loss: 3.1685 - val_accuracy: 0.3450 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
      "Epoch 2/30\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 3.1212 - accuracy: 0.2438 - precision: 0.3932 - recall: 0.0285 - f1score: 0.0509 - val_loss: 2.3080 - val_accuracy: 0.3573 - val_precision: 0.9570 - val_recall: 0.2555 - val_f1score: 0.4017\n",
      "Epoch 3/30\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 2.5126 - accuracy: 0.3584 - precision: 0.8403 - recall: 0.2026 - f1score: 0.3244 - val_loss: 2.0549 - val_accuracy: 0.4452 - val_precision: 0.9178 - val_recall: 0.2857 - val_f1score: 0.4333\n",
      "Epoch 4/30\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 2.2869 - accuracy: 0.4093 - precision: 0.8465 - recall: 0.2695 - f1score: 0.4074 - val_loss: 1.9141 - val_accuracy: 0.4975 - val_precision: 0.9229 - val_recall: 0.2925 - val_f1score: 0.4422\n",
      "Epoch 5/30\n",
      "57/57 [==============================] - 1s 13ms/step - loss: 2.0971 - accuracy: 0.4244 - precision: 0.8495 - recall: 0.3431 - f1score: 0.4875 - val_loss: 1.8365 - val_accuracy: 0.5053 - val_precision: 0.9245 - val_recall: 0.3805 - val_f1score: 0.5357\n",
      "Epoch 6/30\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 1.9972 - accuracy: 0.4301 - precision: 0.8660 - recall: 0.3552 - f1score: 0.5020 - val_loss: 1.7849 - val_accuracy: 0.5125 - val_precision: 0.9122 - val_recall: 0.4258 - val_f1score: 0.5762\n",
      "Epoch 7/30\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 1.9142 - accuracy: 0.4420 - precision: 0.8489 - recall: 0.3620 - f1score: 0.5066 - val_loss: 1.7654 - val_accuracy: 0.5242 - val_precision: 0.9281 - val_recall: 0.4415 - val_f1score: 0.5933\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 1.8783 - accuracy: 0.4502 - precision: 0.8537 - recall: 0.3655 - f1score: 0.5108 - val_loss: 1.7223 - val_accuracy: 0.5237 - val_precision: 0.9188 - val_recall: 0.4540 - val_f1score: 0.6024\n",
      "Epoch 9/30\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 1.8366 - accuracy: 0.4525 - precision: 0.8540 - recall: 0.3777 - f1score: 0.5224 - val_loss: 1.6901 - val_accuracy: 0.5515 - val_precision: 0.9199 - val_recall: 0.4566 - val_f1score: 0.6048\n",
      "Epoch 10/30\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 1.6936 - accuracy: 0.4996 - precision: 0.8702 - recall: 0.4171 - f1score: 0.5624 - val_loss: 1.6457 - val_accuracy: 0.5698 - val_precision: 0.9218 - val_recall: 0.4649 - val_f1score: 0.6121\n",
      "Epoch 11/30\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 1.6685 - accuracy: 0.5102 - precision: 0.8655 - recall: 0.4330 - f1score: 0.5762 - val_loss: 1.6320 - val_accuracy: 0.5921 - val_precision: 0.9195 - val_recall: 0.4680 - val_f1score: 0.6143\n",
      "Epoch 12/30\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 1.6071 - accuracy: 0.5119 - precision: 0.8648 - recall: 0.4361 - f1score: 0.5790 - val_loss: 1.6380 - val_accuracy: 0.5871 - val_precision: 0.8968 - val_recall: 0.4701 - val_f1score: 0.6107\n",
      "Epoch 13/30\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 1.5812 - accuracy: 0.5192 - precision: 0.8542 - recall: 0.4458 - f1score: 0.5852 - val_loss: 1.6188 - val_accuracy: 0.5954 - val_precision: 0.9075 - val_recall: 0.4717 - val_f1score: 0.6146\n",
      "Epoch 14/30\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 1.5393 - accuracy: 0.5286 - precision: 0.8676 - recall: 0.4573 - f1score: 0.5982 - val_loss: 1.6483 - val_accuracy: 0.6043 - val_precision: 0.8968 - val_recall: 0.4821 - val_f1score: 0.6206\n",
      "Epoch 15/30\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 1.5058 - accuracy: 0.5339 - precision: 0.8676 - recall: 0.4661 - f1score: 0.6053 - val_loss: 1.6571 - val_accuracy: 0.6093 - val_precision: 0.8985 - val_recall: 0.4816 - val_f1score: 0.6206\n",
      "Epoch 16/30\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 1.5468 - accuracy: 0.5245 - precision: 0.8625 - recall: 0.4631 - f1score: 0.6016 - val_loss: 1.6804 - val_accuracy: 0.6016 - val_precision: 0.8881 - val_recall: 0.4795 - val_f1score: 0.6163\n",
      "Epoch 17/30\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 1.5355 - accuracy: 0.5164 - precision: 0.8559 - recall: 0.4562 - f1score: 0.5942 - val_loss: 1.6874 - val_accuracy: 0.6105 - val_precision: 0.8830 - val_recall: 0.4915 - val_f1score: 0.6245\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=128, epochs=30, callbacks=[es], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "sharing-stylus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:45:05.060884Z",
     "start_time": "2021-04-22T12:45:04.833480Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 0s 3ms/step - loss: 1.7636 - accuracy: 0.6060 - precision: 0.8660 - recall: 0.5107 - f1score: 0.6388\n"
     ]
    }
   ],
   "source": [
    "_loss, _precision, _accuracy, _recall, _f1score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cellular-stuff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T12:45:05.993949Z",
     "start_time": "2021-04-22T12:45:05.991553Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.764, accuracy: 0.866, precision: 0.606, recall: 0.511, f1 score: 0.639\n"
     ]
    }
   ],
   "source": [
    "print('loss: {:.3f}, accuracy: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1 score: {:.3f}'.format(_loss, _accuracy, _precision, _recall, _f1score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-bunny",
   "metadata": {},
   "source": [
    "### 머신러닝과 딥러닝 모델 비교 (num_words: 1만개)\n",
    "머신러닝 중 가장 성능이 좋았던 ```num_words=None```를 사용하려 하였으나 단어의 수가 너무 커서 에러 메시지가 났다. 그래서 머신러닝과 딥러닝 모델의 단어 수를 1만개로 맞춰주었다. \n",
    "\n",
    "- 머신러닝 모델    \n",
    "정확도: Decision Tree(62%) < 나이브 베이즈(66%) < 랜덤 포레스트 정확도(67%) < 그래디언트 부스팅 트리(76.7%) < CMB(77%) < SVM(77.4%) < 로지스틱 회귀(80.8%) < 보팅(81.2%)\n",
    "f1 score: 나이브 베이즈(57.6%) < Decision Tree(57.8%) < 랜덤 포레스트 정확도(64%) < CMB(75%) < 그래디언트 부스팅 트리(76%) < SVM(77%) < 로지스틱 회귀(80%) < 보팅(80.8%)\n",
    "\n",
    "- 딥러닝 모델(LSTM)    \n",
    "loss: 1.773, accuracy: 0.753, precision: 0.636, recall: 0.592, f1 score: 0.661\n",
    "- 딥러닝 모델(1D-CNN)        \n",
    "loss: 1.760, accuracy: 0.856, precision: 0.565, recall: 0.495, f1 score: 0.624\n",
    "\n",
    "LSTM 모델의 정확도는 75%, f1 score는 66%이고, 1D-CNN 모델의 정확도는 87%, f1 score는 64%이다. 다양한 머신러닝 모델과 비교해 보았을 때, LSTM 모델과 1D-CNN의 f1 score는 중간 정도의 성능을 보여준다. 그러나 딥러닝모델의 경우, 하이퍼파라미터를 조절하거나 레이어를 여러 개 쌓으면 성능이 충분히 올라갈 수 있기 때문에 위의 결과로 어느 모델이 더 좋은 성능을 보인다고는 속단하기는 어려운 것 같다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-gospel",
   "metadata": {},
   "source": [
    "### 루브릭\n",
    "\n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "\n",
    "|평가문항|\t상세기준||\n",
    "|:------:|:--------:|:--------:|\n",
    "|1. 분류 모델의 accuracy가 기준 이상 높게 나왔는가?|코퍼스 분석, 전처리, 3가지 단어 개수에 대해 8가지 머신러닝 기법을 적용하여 그중 최적의 솔루션을 도출하였다.|Y|\n",
    "|2. 분류 모델의 F1 score가 기준 이상 높게 나왔는가?|Vocabulary size에 따른 각 머신러닝 모델의 성능변화 추이를 살피고, 해당 머신러닝 알고리즘의 특성에 근거해 원인을 분석하였다.|Y|\n",
    "|3. 생성모델의 metric(BLEU 등) 기준 이상 높은 성능이 확인되었는가?|동일한 데이터셋과 전처리 조건으로 딥러닝 모델의 성능과 비교하여 결과에 따른 원인을 분석하였다.| Y|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-filing",
   "metadata": {},
   "source": [
    "## 후기\n",
    "### 이번 프로젝트에서 어려웠던 점\n",
    "- 딥러닝 모델을 사용한 다중 분류는 위키독스를 참고하였다. 그런데 처음에 모델이 제대로 작동하지 않아 어려움을 겪었다. 알고보니 embedding에 넣을 인자 때문이었다. 또한 단어의 수(num_words)의 크기가 크면 모델이 제대로 동작되지 않아서 단어의 수를 1만개로 줄여야 했다.\n",
    "\n",
    "### 프로젝트를 진행하면서 알게된 점\n",
    "- 다양한 머신러닝의 종류와 기본적인 개념\n",
    "- num_words의 의미, OOV의 개념 등\n",
    "- 이중분류와 다중분류의 차이점: y_label의 수, 활성화함수(시그모이드 함수/소프트맥스 함수), 손실함수(binary_crossentropy/categorical_crossentropy), 평가 지표(정확도, f1 score)\n",
    "\n",
    "### 프로젝트를 진행하면서 아직 모호한 점\n",
    "다양한 머신러닝 기법에 대해 배웠지만 이론에 대해서는 완벽히 소화하지는 못했다. \n",
    "\n",
    "### 자기 다짐\n",
    "이번 프로젝트까지는 노드에 설명이 자세히 써 있고 참고 자료도 있어서 어렵지 않게 할 수 있었다. 그래서 다른 프로젝트보다 많은 실험을 할 수 있었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-broadcasting",
   "metadata": {},
   "source": [
    "- 참고    \n",
    "https://wikidocs.net/24873    \n",
    "[뷴류성능평가지표](https://sumniya.tistory.com/26)    \n",
    "https://wikidocs.net/22933    \n",
    "[[Keras] 2.0에서 precision,recall 사용하기](http://blog.naver.com/PostView.nhn?blogId=wideeyed&logNo=221226716255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
